{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/siahw/notes/blob/main/%E2%80%9C2_Named_Entity_Recognition_Livecoding_ipynb%E2%80%9D%E7%9A%84%E5%89%AF%E6%9C%AC.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "45a2da87",
      "metadata": {
        "id": "45a2da87"
      },
      "source": [
        "# Named Entity Recognition\n",
        "- For a given word and its context window, estimate whether the given word is location or not"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "11619f5d",
      "metadata": {
        "id": "11619f5d"
      },
      "source": [
        "# 1. Download dataset\n",
        "- CoNLL2003 "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "10a4faa3",
      "metadata": {
        "id": "10a4faa3"
      },
      "outputs": [],
      "source": [
        "!wget https://data.deepai.org/conll2003.zip # Download dataset\n",
        "!unzip conll2003.zip # Unzip dataset zip"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7643dde5",
      "metadata": {
        "id": "7643dde5"
      },
      "source": [
        "## 2. Preprocess Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d31874b2",
      "metadata": {
        "id": "d31874b2",
        "outputId": "1ada555d-61c3-4343-9f18-ca4cdc9a2214"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[\"'s POS B-NP O\",\n",
              " 'representative NN I-NP O',\n",
              " 'to TO B-PP O',\n",
              " 'the DT B-NP O',\n",
              " 'European NNP I-NP B-ORG',\n",
              " 'Union NNP I-NP I-ORG',\n",
              " \"'s POS B-NP O\",\n",
              " 'veterinary JJ I-NP O',\n",
              " 'committee NN I-NP O',\n",
              " 'Werner NNP I-NP B-PER',\n",
              " 'Zwingmann NNP I-NP I-PER',\n",
              " 'said VBD B-VP O',\n",
              " 'on IN B-PP O',\n",
              " 'Wednesday NNP B-NP O',\n",
              " 'consumers NNS I-NP O',\n",
              " 'should MD B-VP O',\n",
              " 'buy VB I-VP O',\n",
              " 'sheepmeat NN B-NP O',\n",
              " 'from IN B-PP O',\n",
              " 'countries NNS B-NP O',\n",
              " 'other JJ B-ADJP O',\n",
              " 'than IN B-PP O',\n",
              " 'Britain NNP B-NP B-LOC',\n",
              " 'until IN B-SBAR O',\n",
              " 'the DT B-NP O',\n",
              " 'scientific JJ I-NP O',\n",
              " 'advice NN I-NP O',\n",
              " 'was VBD B-VP O',\n",
              " 'clearer JJR B-ADJP O',\n",
              " '. . O O']"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "with open(\"train.txt\") as f:\n",
        "  string = ''.join(f.readlines())\n",
        "dataset = string.split('\\n')\n",
        "\n",
        "dataset[50:80]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "49e7f34b",
      "metadata": {
        "scrolled": true,
        "id": "49e7f34b",
        "outputId": "e70798ec-d35b-462f-b238-fab8e8b09d14"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[['-DOCSTART- -X- -X- O'],\n",
              " ['EU NNP B-NP B-ORG',\n",
              "  'rejects VBZ B-VP O',\n",
              "  'German JJ B-NP B-MISC',\n",
              "  'call NN I-NP O',\n",
              "  'to TO B-VP O',\n",
              "  'boycott VB I-VP O',\n",
              "  'British JJ B-NP B-MISC',\n",
              "  'lamb NN I-NP O',\n",
              "  '. . O O'],\n",
              " ['Peter NNP B-NP B-PER', 'Blackburn NNP I-NP I-PER'],\n",
              " ['BRUSSELS NNP B-NP B-LOC', '1996-08-22 CD I-NP O'],\n",
              " ['The DT B-NP O',\n",
              "  'European NNP I-NP B-ORG',\n",
              "  'Commission NNP I-NP I-ORG',\n",
              "  'said VBD B-VP O',\n",
              "  'on IN B-PP O',\n",
              "  'Thursday NNP B-NP O',\n",
              "  'it PRP B-NP O',\n",
              "  'disagreed VBD B-VP O',\n",
              "  'with IN B-PP O',\n",
              "  'German JJ B-NP B-MISC',\n",
              "  'advice NN I-NP O',\n",
              "  'to TO B-PP O',\n",
              "  'consumers NNS B-NP O',\n",
              "  'to TO B-VP O',\n",
              "  'shun VB I-VP O',\n",
              "  'British JJ B-NP B-MISC',\n",
              "  'lamb NN I-NP O',\n",
              "  'until IN B-SBAR O',\n",
              "  'scientists NNS B-NP O',\n",
              "  'determine VBP B-VP O',\n",
              "  'whether IN B-SBAR O',\n",
              "  'mad JJ B-NP O',\n",
              "  'cow NN I-NP O',\n",
              "  'disease NN I-NP O',\n",
              "  'can MD B-VP O',\n",
              "  'be VB I-VP O',\n",
              "  'transmitted VBN I-VP O',\n",
              "  'to TO B-PP O',\n",
              "  'sheep NN B-NP O',\n",
              "  '. . O O']]"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from itertools import groupby\n",
        "\n",
        "dataset_in_sentence = [list(group) for k, group in groupby(dataset, lambda x: x == \"\") if not k]\n",
        "dataset_in_sentence[:5]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "18c29a2a",
      "metadata": {
        "id": "18c29a2a"
      },
      "source": [
        "### 2.1 Make Data Loader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8a4d1fbc",
      "metadata": {
        "scrolled": true,
        "id": "8a4d1fbc",
        "outputId": "e6f9ca42-b872-4350-e529-075139a3c632"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['The DT B-NP O', 'European NNP I-NP B-ORG', 'Commission NNP I-NP I-ORG', 'said VBD B-VP O', 'on IN B-PP O', 'Thursday NNP B-NP O', 'it PRP B-NP O', 'disagreed VBD B-VP O', 'with IN B-PP O', 'German JJ B-NP B-MISC', 'advice NN I-NP O', 'to TO B-PP O', 'consumers NNS B-NP O', 'to TO B-VP O', 'shun VB I-VP O', 'British JJ B-NP B-MISC', 'lamb NN I-NP O', 'until IN B-SBAR O', 'scientists NNS B-NP O', 'determine VBP B-VP O', 'whether IN B-SBAR O', 'mad JJ B-NP O', 'cow NN I-NP O', 'disease NN I-NP O', 'can MD B-VP O', 'be VB I-VP O', 'transmitted VBN I-VP O', 'to TO B-PP O', 'sheep NN B-NP O', '. . O O']\n",
            "['PAD', 'PAD', 'the', 'european', 'commission']\n"
          ]
        }
      ],
      "source": [
        "window_size = 2 \n",
        "sentence = dataset_in_sentence[4]\n",
        "word_idx = 0\n",
        "center_word = sentence[2].split(' ')[0]\n",
        "\n",
        "# from word_idx - window_length until word_idx + window_length\n",
        "def get_words_window(sentence, word_idx, window_size):\n",
        "  idx_range = range( max(word_idx-window_size, 0), min(word_idx+window_size+1, len(sentence)))\n",
        "  windowed_words = [sentence[idx].split(' ')[0].lower() for idx in idx_range]\n",
        "  \n",
        "  if word_idx < window_size:\n",
        "    windowed_words = ['PAD'] * (window_size-word_idx) + windowed_words\n",
        "  if word_idx + window_size >= len(sentence):\n",
        "    windowed_words += ['PAD'] * (word_idx + window_size -len(sentence)+1)\n",
        "  \n",
        "  assert len(windowed_words) == 1+window_size*2, \"The length of output has to follow window size\"\n",
        "  return windowed_words\n",
        "\n",
        "print(sentence)\n",
        "print(get_words_window(sentence, word_idx, window_size))\n",
        "# center_word"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d1c52b6c",
      "metadata": {
        "id": "d1c52b6c"
      },
      "outputs": [],
      "source": [
        "import gensim.downloader\n",
        "\n",
        "wrd2vec = gensim.downloader.load(\"glove-wiki-gigaword-300\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b5a0f80d",
      "metadata": {
        "id": "b5a0f80d",
        "outputId": "b665c090-3d3b-4b05-f8cf-68a6c5777f1a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['PAD', 'PAD', 'the', 'european', 'commission']\n",
            "the [ 0.04656    0.21318   -0.0074364 -0.45854   -0.035639   0.23643\n",
            " -0.28836    0.21521   -0.13486   -1.6413   ]\n",
            "european [ 0.37636   0.1245    0.13028   0.024309  0.50706   0.18205  -0.44874\n",
            "  0.35522   0.27065  -2.2199  ]\n",
            "commission [ 4.7286e-01 -3.9634e-01 -2.6584e-01  1.2371e-02 -2.5906e-01 -2.5823e-01\n",
            "  1.1492e-01 -1.4363e-01  2.0568e-03 -2.2627e+00]\n"
          ]
        }
      ],
      "source": [
        "word_idx = 0\n",
        "words_window = get_words_window(sentence, word_idx, window_size)\n",
        "print(words_window)\n",
        "for word in words_window:\n",
        "  if word in wrd2vec:\n",
        "    print(word , wrd2vec[word][:10])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5a6bd62c",
      "metadata": {
        "id": "5a6bd62c",
        "outputId": "7da740b4-b1e1-4ed5-a9ca-091150371cf5"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipykernel_1451512/4286083826.py:7: UserWarning: The given NumPy array is not writable, and PyTorch does not support non-writable tensors. This means writing to this tensor will result in undefined behavior. You may want to copy the array to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  ../torch/csrc/utils/tensor_numpy.cpp:178.)\n",
            "  concat_vector.append(torch.Tensor(wrd2vec[word]))\n"
          ]
        }
      ],
      "source": [
        "# concat vectors\n",
        "import torch\n",
        "\n",
        "concat_vector = []\n",
        "for word in words_window:\n",
        "  if word in wrd2vec:\n",
        "    concat_vector.append(torch.Tensor(wrd2vec[word]))\n",
        "  else:\n",
        "    zero_vector = torch.zeros(300)\n",
        "    concat_vector.append(zero_vector)\n",
        "\n",
        "concat_tensor = torch.cat(concat_vector)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a52c7369",
      "metadata": {
        "id": "a52c7369",
        "outputId": "7c858d13-15ee-4ce7-f060-e6fdb8e1668e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor(True)"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "def make_flattened_vector_for_words_window(words_window):\n",
        "  '''\n",
        "  words_window (list): A list of words, with length 1+window_size*2\n",
        "  '''\n",
        "  output = [torch.Tensor(wrd2vec[word]) if word in wrd2vec else torch.zeros(300) for word in words_window ]\n",
        "  \n",
        "  return torch.cat(output)\n",
        "\n",
        "'''\n",
        "If you want to compare two tensors, and make sure those two tensors are exactly same (for every dimension)\n",
        "you can use abooltensor.all()\n",
        "'''\n",
        "bool_tensor = concat_tensor == make_flattened_vector_for_words_window(words_window)\n",
        "bool_tensor.all()\n",
        "# (concat_tensor == make_flattened_vector_for_words_window(words_window)).all()\n",
        "  \n",
        "  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "401cc7a0",
      "metadata": {
        "id": "401cc7a0"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d5cc5ff0",
      "metadata": {
        "id": "d5cc5ff0",
        "outputId": "32605d5c-ec95-4220-c553-b16ed942c57b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(False)\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "\"\\n[300 300 300 300 300]\\n1500 \\n\\nconcat_tensor's 1200th dimension\\n= 0th dimension of the 4th word\\n\\nconcat_tensor's 50th dimension\\n= 50th dimension of the 0th word\\n\\nconcat_tensor's 350th dimension\\n= 50th dimension of the 1st word\\n\\n\\n\""
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "concat_tensor = torch.cat(concat_vector)\n",
        "\n",
        "print(concat_tensor[650] == concat_vector[2][49])\n",
        "'''\n",
        "[300 300 300 300 300]\n",
        "1500 \n",
        "\n",
        "concat_tensor's 1200th dimension\n",
        "= 0th dimension of the 4th word\n",
        "\n",
        "concat_tensor's 50th dimension\n",
        "= 50th dimension of the 0th word\n",
        "\n",
        "concat_tensor's 350th dimension\n",
        "= 50th dimension of the 1st word\n",
        "\n",
        "\n",
        "'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e89c74c8",
      "metadata": {
        "id": "e89c74c8"
      },
      "outputs": [],
      "source": [
        "import torch.nn as nn\n",
        "\n",
        "hidden_size = 128\n",
        "first_layer = nn.Linear(300*5, 128, bias=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d62884d5",
      "metadata": {
        "id": "d62884d5",
        "outputId": "a2f63451-a84b-44d1-c9d2-a46e14727397"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([128, 1500])"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "first_layer.weight.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ee1beaec",
      "metadata": {
        "id": "ee1beaec",
        "outputId": "f343a163-de7f-4009-8f54-78add6064c0a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([128])"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "first_layer.bias.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6b2d23ea",
      "metadata": {
        "id": "6b2d23ea",
        "outputId": "5b429572-6a80-4d53-a6b1-a5f7dfcab7b4"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(torch.Size([1500]), torch.Size([128]))"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "hidden = first_layer(concat_tensor)\n",
        "concat_tensor.shape, hidden.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1772c2c6",
      "metadata": {
        "id": "1772c2c6",
        "outputId": "019fa534-f1c9-4502-d635-94f39b6e95f5"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([-0.0682, -0.0923, -0.0940,  0.0756, -0.0175, -0.3025,  0.0945, -0.2570,\n",
              "        -0.0983, -0.1161,  0.1883, -0.0350,  0.4268, -0.2735, -0.1689,  0.0428,\n",
              "        -0.1761, -0.0236,  0.0563,  0.0217,  0.0363,  0.0156,  0.0044, -0.0684,\n",
              "        -0.0430,  0.0631,  0.2835,  0.0891,  0.1542,  0.0012, -0.1917, -0.3575,\n",
              "         0.0321, -0.1149,  0.0270,  0.1977,  0.1497,  0.1066, -0.0751, -0.1109,\n",
              "        -0.2169,  0.3070, -0.0943, -0.1034, -0.2323, -0.1022,  0.1495,  0.1178,\n",
              "         0.1320,  0.0252,  0.1438,  0.0259,  0.0027, -0.2526,  0.2652,  0.0737,\n",
              "        -0.0136, -0.0559, -0.0364,  0.0574,  0.0576,  0.0747,  0.1169, -0.0582,\n",
              "        -0.0546,  0.2745, -0.0195,  0.0427,  0.0931,  0.2615,  0.0027,  0.2862,\n",
              "         0.0875, -0.1327,  0.0058, -0.1183,  0.0258, -0.0506, -0.1921, -0.3698,\n",
              "         0.1010, -0.2236, -0.0598,  0.0293, -0.0462,  0.0794, -0.0231,  0.1567,\n",
              "         0.0183, -0.0155, -0.1726,  0.2906, -0.0280, -0.0679, -0.1953, -0.1351,\n",
              "         0.1173,  0.2281,  0.1474, -0.3652, -0.1338, -0.1366,  0.0730,  0.0415,\n",
              "        -0.0837, -0.0380, -0.1533, -0.0966, -0.0699,  0.0241,  0.1150, -0.3845,\n",
              "         0.1870,  0.0967, -0.1095, -0.0138,  0.1518,  0.0985,  0.0776, -0.0763,\n",
              "         0.3787,  0.1864, -0.0199, -0.0136, -0.0413,  0.1356,  0.0373, -0.0134],\n",
              "       grad_fn=<AddBackward0>)"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "\n",
        "wx = torch.matmul(first_layer.weight, concat_tensor) \n",
        "b = first_layer.bias\n",
        "\n",
        "wx+b"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4cd5e5c2",
      "metadata": {
        "id": "4cd5e5c2",
        "outputId": "6aa0722a-9882-41b5-9671-76f7b0d451a2"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([-0.0682, -0.0923, -0.0940,  0.0756, -0.0175, -0.3025,  0.0945, -0.2570,\n",
              "        -0.0983, -0.1161,  0.1883, -0.0350,  0.4268, -0.2735, -0.1689,  0.0428,\n",
              "        -0.1761, -0.0236,  0.0563,  0.0217,  0.0363,  0.0156,  0.0044, -0.0684,\n",
              "        -0.0430,  0.0631,  0.2835,  0.0891,  0.1542,  0.0012, -0.1917, -0.3575,\n",
              "         0.0321, -0.1149,  0.0270,  0.1977,  0.1497,  0.1066, -0.0751, -0.1109,\n",
              "        -0.2169,  0.3070, -0.0943, -0.1034, -0.2323, -0.1022,  0.1495,  0.1178,\n",
              "         0.1320,  0.0252,  0.1438,  0.0259,  0.0027, -0.2526,  0.2652,  0.0737,\n",
              "        -0.0136, -0.0559, -0.0364,  0.0574,  0.0576,  0.0747,  0.1169, -0.0582,\n",
              "        -0.0546,  0.2745, -0.0195,  0.0427,  0.0931,  0.2615,  0.0027,  0.2862,\n",
              "         0.0875, -0.1327,  0.0058, -0.1183,  0.0258, -0.0506, -0.1921, -0.3698,\n",
              "         0.1010, -0.2236, -0.0598,  0.0293, -0.0462,  0.0794, -0.0231,  0.1567,\n",
              "         0.0183, -0.0155, -0.1726,  0.2906, -0.0280, -0.0679, -0.1953, -0.1351,\n",
              "         0.1173,  0.2281,  0.1474, -0.3652, -0.1338, -0.1366,  0.0730,  0.0415,\n",
              "        -0.0837, -0.0380, -0.1533, -0.0966, -0.0699,  0.0241,  0.1150, -0.3845,\n",
              "         0.1870,  0.0967, -0.1095, -0.0138,  0.1518,  0.0985,  0.0776, -0.0763,\n",
              "         0.3787,  0.1864, -0.0199, -0.0136, -0.0413,  0.1356,  0.0373, -0.0134],\n",
              "       grad_fn=<AddBackward0>)"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "first_layer(concat_tensor)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9af99d70",
      "metadata": {
        "id": "9af99d70",
        "outputId": "d6a7689e-4a32-4807-ec27-3bb7dc16404e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([128, 1500])\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "tensor([-0.0234, -0.0016,  0.0245,  ..., -0.0140,  0.0228,  0.0244],\n",
              "       grad_fn=<SelectBackward0>)"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "print(first_layer.weight.shape)\n",
        "first_layer.weight[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "86ab205d",
      "metadata": {
        "scrolled": true,
        "id": "86ab205d"
      },
      "outputs": [],
      "source": [
        "entire_output = []\n",
        "for neuron in first_layer.weight:\n",
        "  entire_output.append((neuron * concat_tensor).sum())\n",
        "# entire_output\n",
        "                    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b03c750c",
      "metadata": {
        "id": "b03c750c",
        "outputId": "27c6961b-1228-44bd-eceb-b20fb29979a1"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['PAD', 'PAD', 'the', 'european', 'commission']"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "words_window"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f6dbee12",
      "metadata": {
        "scrolled": true,
        "id": "f6dbee12",
        "outputId": "eeb40cd3-a372-4001-d50a-d72c34305401"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([ 1.8404e-02, -3.4393e-03,  1.2680e-02,  1.0789e-02,  2.4724e-02,\n",
              "         2.0654e-02, -4.6074e-03,  9.9631e-03, -1.1547e-02,  2.5176e-02,\n",
              "         9.3105e-03,  2.0875e-02,  6.1576e-03,  1.3280e-03, -1.9320e-02,\n",
              "         3.2641e-03,  1.0713e-03, -2.1077e-02, -1.3388e-02,  1.6420e-02,\n",
              "        -8.8603e-03,  1.2601e-02, -2.4617e-02, -1.7217e-03, -1.4043e-02,\n",
              "         2.2048e-02, -7.0111e-03,  3.1020e-03,  1.4639e-02,  2.2705e-02,\n",
              "         5.4842e-03, -1.6591e-02, -1.6450e-02, -2.2884e-02,  1.3556e-03,\n",
              "        -1.9342e-02, -3.0844e-03,  1.2723e-02,  1.0531e-02, -8.8435e-03,\n",
              "         1.2381e-02, -6.8721e-03,  7.5555e-03,  1.1064e-02,  1.5248e-02,\n",
              "         2.1598e-02, -1.4893e-02,  2.0339e-02, -5.3582e-03,  2.4540e-02,\n",
              "         9.8794e-03, -1.5995e-03, -6.6877e-03,  1.7079e-02,  3.4734e-03,\n",
              "         2.2441e-03, -1.3161e-02, -2.0857e-02,  2.2771e-03, -2.4354e-03,\n",
              "         1.9574e-02, -2.3609e-02,  4.6484e-04, -1.3442e-03, -2.5218e-02,\n",
              "         3.1336e-03, -1.0709e-03, -2.7058e-03,  1.1269e-02,  1.6376e-02,\n",
              "        -5.6799e-03, -1.0760e-02,  1.5046e-02, -2.0044e-02,  1.0390e-02,\n",
              "        -2.2913e-02,  4.3005e-03,  1.4411e-02, -6.9677e-03,  1.8531e-02,\n",
              "        -5.6630e-03, -2.4498e-02, -1.0629e-02, -1.9634e-02, -1.1434e-02,\n",
              "        -2.7090e-03, -1.7934e-02, -1.0526e-02,  1.5943e-02,  1.5836e-02,\n",
              "        -2.1837e-02, -8.5131e-03, -6.6949e-03, -1.5462e-02,  2.5603e-02,\n",
              "        -1.6212e-02, -1.4360e-02,  5.2123e-03,  7.9710e-03,  1.9979e-02,\n",
              "         2.2785e-02, -8.7387e-04,  5.0833e-03,  5.6575e-03, -1.2585e-02,\n",
              "         5.6108e-05,  6.8710e-03,  2.0651e-03, -4.8565e-03,  2.1140e-02,\n",
              "        -1.7278e-02, -1.4110e-02, -2.5588e-02, -1.8632e-02, -6.9808e-04,\n",
              "        -1.3517e-03, -9.4599e-03,  1.1345e-02, -2.0940e-02,  6.4844e-03,\n",
              "        -3.0632e-03,  1.2351e-02, -2.1026e-02,  2.4543e-02, -2.0213e-02,\n",
              "         1.6872e-02, -1.9031e-02,  2.1486e-02, -2.3305e-02,  7.8264e-03,\n",
              "         3.5267e-03, -1.2409e-02,  1.0925e-02, -1.6938e-02, -2.3004e-02,\n",
              "         1.9440e-02, -2.1305e-02,  1.2343e-02,  2.4944e-02, -1.7160e-02,\n",
              "        -2.4338e-02,  2.1103e-02, -1.7935e-02, -1.1369e-03, -1.2694e-02,\n",
              "         1.4929e-02,  4.5850e-03,  5.7325e-04, -2.0888e-02, -1.8908e-02,\n",
              "         1.1299e-02,  2.9103e-03,  1.9055e-02,  2.0394e-02, -2.4382e-02,\n",
              "         1.4680e-02,  1.5490e-02,  2.2962e-03, -2.1041e-02,  1.0880e-02,\n",
              "         3.5470e-03, -1.5568e-02,  1.3308e-02,  2.7859e-03, -2.5045e-02,\n",
              "        -2.6033e-03,  9.5817e-03,  1.9196e-02,  2.0776e-02, -7.3691e-03,\n",
              "        -1.8074e-02,  2.0320e-02, -1.7206e-02,  7.2160e-03, -1.9831e-02,\n",
              "         1.6955e-02,  1.5477e-02,  4.1914e-03, -7.6739e-03, -1.0488e-04,\n",
              "         2.2775e-02, -7.2760e-03,  2.3086e-02, -2.4670e-02, -2.0601e-02,\n",
              "         1.1496e-02,  2.4547e-02,  1.5697e-02,  2.3800e-03, -1.1265e-02,\n",
              "         2.5347e-02, -9.9673e-03,  8.9447e-03,  6.5219e-03,  1.1987e-02,\n",
              "         1.7288e-02, -2.3593e-02,  7.8635e-03, -1.9533e-02,  2.5477e-02,\n",
              "         4.5839e-03,  2.3947e-02, -8.6090e-03, -2.4771e-02, -2.5746e-02,\n",
              "        -1.5091e-02,  2.5133e-02, -3.0051e-03, -1.0800e-02, -6.5737e-03,\n",
              "        -1.4258e-02,  1.3900e-03,  1.2124e-02,  2.4758e-02, -2.6594e-03,\n",
              "         2.0526e-02,  2.9446e-03,  1.1201e-02, -1.6366e-02, -1.3348e-02,\n",
              "        -2.5409e-02,  2.5158e-02,  1.5671e-02,  2.4730e-02, -5.3425e-03,\n",
              "         1.7096e-02, -2.0084e-02,  5.2547e-03, -6.8736e-03,  6.1126e-03,\n",
              "         2.3024e-03,  2.5330e-02, -1.3289e-02,  2.7057e-03,  8.4278e-03,\n",
              "        -1.2352e-02, -1.6297e-02, -7.1020e-03,  1.7321e-02, -5.4258e-03,\n",
              "        -1.1198e-03,  1.4964e-02,  4.1031e-03,  1.6661e-02,  2.5061e-02,\n",
              "         1.3565e-02, -1.6040e-02,  1.1868e-03,  1.9319e-02,  9.9670e-03,\n",
              "        -5.5261e-03, -6.5468e-03, -6.0794e-03,  1.9682e-02, -1.4071e-02,\n",
              "         1.4916e-02, -5.6807e-03, -1.7750e-02,  1.1381e-02,  9.5076e-03,\n",
              "         1.9177e-02,  1.8468e-02,  1.7095e-02, -1.0956e-02,  6.6120e-03,\n",
              "         1.1023e-02, -1.9904e-04,  2.3618e-02,  2.0824e-02, -3.6555e-03,\n",
              "        -2.4372e-02,  2.6093e-03, -1.6578e-02,  3.3199e-04,  1.4494e-02,\n",
              "        -4.4196e-03,  3.9801e-03,  7.8229e-03,  2.3623e-02,  1.3186e-02,\n",
              "         1.2083e-02, -3.0356e-03, -1.8076e-02, -1.3250e-02, -8.3666e-03,\n",
              "        -1.5830e-02,  9.1000e-03, -1.4882e-03,  1.3352e-02,  5.7154e-03,\n",
              "         1.6021e-02, -1.2095e-02, -1.6358e-02, -2.0751e-02,  1.0067e-03,\n",
              "         6.4489e-03,  1.8187e-03, -7.6911e-03,  2.0633e-02,  7.6634e-04],\n",
              "       grad_fn=<SliceBackward0>)"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "first_layer.weight[0][600:900]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d8347386",
      "metadata": {
        "scrolled": true,
        "id": "d8347386",
        "outputId": "62c5cc51-3f03-4d6b-9b9c-4c1c42912c4d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(tensor([-0.0682, -0.0923, -0.0940,  0.0756, -0.0175, -0.3025,  0.0945, -0.2570,\n",
              "         -0.0983, -0.1161,  0.1883, -0.0350,  0.4268, -0.2735, -0.1689,  0.0428,\n",
              "         -0.1761, -0.0236,  0.0563,  0.0217], grad_fn=<SliceBackward0>),\n",
              " tensor([0.0000, 0.0000, 0.0000, 0.0756, 0.0000, 0.0000, 0.0945, 0.0000, 0.0000,\n",
              "         0.0000, 0.1883, 0.0000, 0.4268, 0.0000, 0.0000, 0.0428, 0.0000, 0.0000,\n",
              "         0.0563, 0.0217], grad_fn=<SliceBackward0>))"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "hidden = first_layer(concat_tensor)\n",
        "hidden_after_activation = torch.relu(hidden)\n",
        "hidden[:20], hidden_after_activation[:20]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9794d994",
      "metadata": {
        "id": "9794d994",
        "outputId": "5f293ffb-25ee-45b2-c3b9-777792026516"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([128])"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "hidden.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ac60ded7",
      "metadata": {
        "id": "ac60ded7"
      },
      "outputs": [],
      "source": [
        "second_layer = nn.Linear(in_features=128, out_features=1, bias=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "944dd4ea",
      "metadata": {
        "id": "944dd4ea",
        "outputId": "bf55daa5-a327-47ae-edea-77531908149c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(['PAD', 'PAD', 'the', 'european', 'commission'],\n",
              " tensor([0.5187], grad_fn=<SigmoidBackward0>))"
            ]
          },
          "execution_count": 23,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "second_output = second_layer(hidden_after_activation)\n",
        "final_prediction = torch.sigmoid(second_output)\n",
        "words_window, final_prediction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "31b894da",
      "metadata": {
        "id": "31b894da",
        "outputId": "3fbd18e3-336c-413d-e76b-14e14ba49ba6"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([0.5000])"
            ]
          },
          "execution_count": 24,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "torch.sigmoid(torch.zeros(1))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d1717281",
      "metadata": {
        "id": "d1717281",
        "outputId": "27666dce-0647-44cc-98fe-caf0a8b529c9"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['PAD', 'PAD', 'the', 'european', 'commission']"
            ]
          },
          "execution_count": 25,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "get_words_window(sentence, word_idx, window_size)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "97b788b1",
      "metadata": {
        "id": "97b788b1",
        "outputId": "4dfa0e8b-9724-4315-94b8-18c48c860e73"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['The DT B-NP O',\n",
              " 'European NNP I-NP B-ORG',\n",
              " 'Commission NNP I-NP I-ORG',\n",
              " 'said VBD B-VP O',\n",
              " 'on IN B-PP O']"
            ]
          },
          "execution_count": 26,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "sentence[:5]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f4fffd28",
      "metadata": {
        "id": "f4fffd28"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d3f8b574",
      "metadata": {
        "id": "d3f8b574"
      },
      "source": [
        "## 3. Make a Neural Network Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "05ef02f4",
      "metadata": {
        "id": "05ef02f4",
        "outputId": "1a7066fe-eea3-436e-98f0-812360e60678"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class '__main__.NERModel'>\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "tensor([0.4959], grad_fn=<SigmoidBackward0>)"
            ]
          },
          "execution_count": 27,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "class NERModel(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.first_layer = nn.Linear(in_features=1500, out_features=128)\n",
        "    self.second_layer = nn.Linear(in_features=128, out_features=1)\n",
        "    \n",
        "  def forward(self, x):\n",
        "#     print(\"forward is called\")\n",
        "#     print(x)\n",
        "    hidden_representation = self.first_layer(x)\n",
        "    hidden_after_activation = torch.relu(hidden_representation)\n",
        "    scalar_value = self.second_layer(hidden_after_activation)\n",
        "    probability = torch.sigmoid(scalar_value)\n",
        "    return probability\n",
        "  \n",
        "\n",
        "model = NERModel()\n",
        "print(type(model))\n",
        "model(concat_tensor)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4dce10ae",
      "metadata": {
        "id": "4dce10ae"
      },
      "outputs": [],
      "source": [
        "class NERModelWord(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.first_word = nn.Linear(in_features=300, out_features=128)\n",
        "    self.second_word = nn.Linear(300, 128)\n",
        "    self.third_word = nn.Linear(300, 128)\n",
        "    self.fourth_word = nn.Linear(300, 128)\n",
        "    self.fifth_word = nn.Linear(300, 128)\n",
        "    \n",
        "    self.sixth_word = nn.Linear(300, 128)\n",
        "\n",
        "    self.first_layer = nn.Linear(in_features=1800, out_features=128)\n",
        "    self.second_layer = nn.Linear(in_features=128, out_features=1)\n",
        "    \n",
        "  def forward(self, x1, x2, x3, x4, x5):\n",
        "#     print(\"forward is called\")\n",
        "#     print(x)\n",
        "    \n",
        "    \n",
        "#     hidden_representation = self.first_layer(x)\n",
        "    hidden_representation = self.first_word(x1) + self.second_word(x2) ~ \n",
        "\n",
        "    hidden_after_activation = torch.relu(hidden_representation)\n",
        "    scalar_value = self.second_layer(hidden_after_activation)\n",
        "    probability = torch.sigmoid(scalar_value)\n",
        "    return probability"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c85a3ba8",
      "metadata": {
        "id": "c85a3ba8"
      },
      "source": [
        "## 4. Implement a train loop"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "74b595af",
      "metadata": {
        "id": "74b595af",
        "outputId": "a25c0883-5e7d-4c36-a75c-8ffc6941b1c1"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'\\nFor Epoch in NumEpochs:\\n  For DataSample in TrainingSet:\\n    TrainWithDataSample(Model, DataSample)\\n\\n'"
            ]
          },
          "execution_count": 28,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "'''\n",
        "For Epoch in NumEpochs:\n",
        "  For DataSample in TrainingSet:\n",
        "    TrainWithDataSample(Model, DataSample)\n",
        "\n",
        "'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6750b643",
      "metadata": {
        "id": "6750b643",
        "outputId": "c8589592-eb6a-4183-bb8a-25ac4a4e7a9f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['The DT B-NP O',\n",
              " 'European NNP I-NP B-ORG',\n",
              " 'Commission NNP I-NP I-ORG',\n",
              " 'said VBD B-VP O',\n",
              " 'on IN B-PP O',\n",
              " 'Thursday NNP B-NP O',\n",
              " 'it PRP B-NP O',\n",
              " 'disagreed VBD B-VP O',\n",
              " 'with IN B-PP O',\n",
              " 'German JJ B-NP B-MISC',\n",
              " 'advice NN I-NP O',\n",
              " 'to TO B-PP O',\n",
              " 'consumers NNS B-NP O',\n",
              " 'to TO B-VP O',\n",
              " 'shun VB I-VP O',\n",
              " 'British JJ B-NP B-MISC',\n",
              " 'lamb NN I-NP O',\n",
              " 'until IN B-SBAR O',\n",
              " 'scientists NNS B-NP O',\n",
              " 'determine VBP B-VP O',\n",
              " 'whether IN B-SBAR O',\n",
              " 'mad JJ B-NP O',\n",
              " 'cow NN I-NP O',\n",
              " 'disease NN I-NP O',\n",
              " 'can MD B-VP O',\n",
              " 'be VB I-VP O',\n",
              " 'transmitted VBN I-VP O',\n",
              " 'to TO B-PP O',\n",
              " 'sheep NN B-NP O',\n",
              " '. . O O']"
            ]
          },
          "execution_count": 29,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dataset_in_sentence[4]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "936e1c90",
      "metadata": {
        "id": "936e1c90"
      },
      "outputs": [],
      "source": [
        "loss_fn = torch.nn.BCELoss()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d163bc90",
      "metadata": {
        "id": "d163bc90",
        "outputId": "7822076a-199b-4b3e-aa6d-3b3ddd366704"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.6931471805599453"
            ]
          },
          "execution_count": 31,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from math import log\n",
        "-log(0.5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6dd30951",
      "metadata": {
        "scrolled": true,
        "id": "6dd30951",
        "outputId": "20131847-4215-4688-f05b-2ff01ef3ba08"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.6560989022254944\n",
            "0.6399050354957581\n",
            "0.6489315032958984\n",
            "0.8474754691123962\n",
            "0.5633457899093628\n",
            "0.9032095074653625\n",
            "0.5906470417976379\n",
            "0.5854349136352539\n",
            "0.5068738460540771\n",
            "0.5365739464759827\n",
            "0.46314737200737\n",
            "0.47467195987701416\n",
            "0.5720842480659485\n",
            "0.3640608787536621\n",
            "0.2275027483701706\n",
            "0.3622237741947174\n",
            "0.30291855335235596\n",
            "0.21142800152301788\n",
            "1.108893632888794\n",
            "0.792802631855011\n",
            "0.23962511122226715\n",
            "0.6343240737915039\n",
            "0.48289063572883606\n",
            "0.839089572429657\n",
            "0.25012698769569397\n",
            "0.25959694385528564\n",
            "0.21995367109775543\n",
            "0.3456287086009979\n",
            "0.11637412011623383\n",
            "0.19501881301403046\n"
          ]
        }
      ],
      "source": [
        "model = NERModel()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "'''\n",
        "on-the-fly method to get a data sample\n",
        "'''\n",
        "for sentence in dataset_in_sentence[:30]:\n",
        "  for wrd_idx in range(len(sentence)):\n",
        "    words_window = get_words_window(sentence, wrd_idx, 2)\n",
        "    flattened_vector = make_flattened_vector_for_words_window(words_window)\n",
        "    prediction = model(flattened_vector)\n",
        "    \n",
        "    label = sentence[wrd_idx].split(' ')[-1] in ('B-LOC', 'I-LOC')\n",
        "    label_tensor = torch.Tensor([label]).float()\n",
        "    loss = loss_fn(prediction, label_tensor) # Calculate loss\n",
        "    loss.backward() # Backpropagate the loss to get the gradient\n",
        "    optimizer.step() # Update the parameters\n",
        "    optimizer.zero_grad() # Reset the gradient of the parameters\n",
        "    print(loss.item())\n",
        "#     print(prediction.item(), label_tensor, loss.item())\n",
        "#     print(words_window, prediction, label)\n",
        "    break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4e534c68",
      "metadata": {
        "id": "4e534c68",
        "outputId": "0b5d64ef-0458-4495-f663-b5314c504280"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'\\nPrepare training data before we start the training stage\\n'"
            ]
          },
          "execution_count": 33,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "'''\n",
        "Prepare training data before we start the training stage\n",
        "'''\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2868525f",
      "metadata": {
        "id": "2868525f"
      },
      "outputs": [],
      "source": [
        "def prepare_dataset(dataset_in_sentence):\n",
        "  total_data_sample = []\n",
        "  for sentence in dataset_in_sentence[:100]:\n",
        "    for wrd_idx in range(len(sentence)):\n",
        "      words_window = get_words_window(sentence, wrd_idx, 2)\n",
        "      flattened_vector = make_flattened_vector_for_words_window(words_window)    \n",
        "      label = sentence[wrd_idx].split(' ')[-1] in ('B-LOC', 'I-LOC')\n",
        "      data_sample = (flattened_vector, label)\n",
        "      total_data_sample.append(data_sample)\n",
        "  return total_data_sample\n",
        "\n",
        "total_data_sample = prepare_dataset(dataset_in_sentence)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "166aae1b",
      "metadata": {
        "scrolled": true,
        "id": "166aae1b",
        "outputId": "6f1b0b76-e6cc-484a-f437-5997832f3606"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(1529,\n",
              " (tensor([-0.4737, -0.1800, -0.4015,  ...,  1.0656, -0.0622,  0.4095]), False))"
            ]
          },
          "execution_count": 35,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(total_data_sample), total_data_sample[400]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e753aa53",
      "metadata": {
        "id": "e753aa53"
      },
      "outputs": [],
      "source": [
        "class WindowWordDataset:\n",
        "  def __init__(self, txt_path):\n",
        "    \n",
        "    with open(txt_path) as f:\n",
        "      string = ''.join(f.readlines())\n",
        "    dataset = string.split('\\n')\n",
        "    self.data_in_sentence = [list(group) for k, group in groupby(dataset, lambda x: x == \"\") if not k]\n",
        "    self.data_samples = self.prepare_entire_data_sample()\n",
        "    \n",
        "  def prepare_entire_data_sample(self):\n",
        "    total_data_sample = []\n",
        "    for sentence in self.data_in_sentence:\n",
        "      for wrd_idx in range(len(sentence)):\n",
        "        words_window = get_words_window(sentence, wrd_idx, 2)\n",
        "        flattened_vector = make_flattened_vector_for_words_window(words_window)    \n",
        "        label = sentence[wrd_idx].split(' ')[-1] in ('B-LOC', 'I-LOC')\n",
        "        data_sample = (flattened_vector, label, words_window)\n",
        "        total_data_sample.append(data_sample)\n",
        "    return total_data_sample\n",
        "  \n",
        "  def __len__(self):\n",
        "    return len(self.data_samples)\n",
        "  \n",
        "  def __getitem__(self, idx):\n",
        "    return self.data_samples[idx][:2]\n",
        "  \n",
        "dataset = WindowWordDataset('train.txt')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "470e4f67",
      "metadata": {
        "id": "470e4f67",
        "outputId": "2f223555-c4c0-464d-8b5d-51cb58d161f4"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "204567"
            ]
          },
          "execution_count": 37,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "37081654",
      "metadata": {
        "scrolled": false,
        "id": "37081654",
        "outputId": "ccb2abf2-01e3-45c2-988b-9a632020d857"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(tensor([ 1.0857,  0.1658, -0.7905,  ...,  0.0020,  0.7095,  0.2967]), False)"
            ]
          },
          "execution_count": 38,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dataset[245]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5881a8a1",
      "metadata": {
        "scrolled": true,
        "id": "5881a8a1",
        "outputId": "fe6081ee-e25a-4c32-f1ac-149e9c677303"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(tensor([[-0.7199,  0.0743,  0.3479,  ..., -0.4654, -0.1551,  0.4396],\n",
              "         [-0.3062,  0.0885,  0.0152,  ..., -0.0091, -0.0848, -0.0733],\n",
              "         [ 0.0466,  0.2132, -0.0074,  ..., -0.2441, -0.0308, -0.0318],\n",
              "         ...,\n",
              "         [-0.2413,  0.1513,  0.0168,  ...,  0.0000,  0.0000,  0.0000],\n",
              "         [ 0.2887, -0.1602,  0.0302,  ..., -0.1604,  0.0467, -0.0706],\n",
              "         [ 0.0000,  0.0000,  0.0000,  ...,  0.1541,  0.4886,  0.1367]]),\n",
              " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]))"
            ]
          },
          "execution_count": 39,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from torch.utils.data import DataLoader\n",
        "\n",
        "def custom_collate_fn(raw_batch):\n",
        "  '''\n",
        "  collate raw batch (a list of tuple data sample)\n",
        "  '''\n",
        "  \n",
        "  input_vectors = []\n",
        "  labels = []\n",
        "  for data_sample in raw_batch:\n",
        "    input_vector = data_sample[0]\n",
        "    label = data_sample[1]\n",
        "    \n",
        "    input_vectors.append(input_vector)\n",
        "    labels.append(label)\n",
        "#   print(input_vectors)\n",
        "#   print(labels)\n",
        "  \n",
        "  input_tensor = torch.stack(input_vectors) # stack a list of tensor into a new dimension\n",
        "#   concat_tensor = torch.cat(input_vectors) # this concatenate to an existing dimension\n",
        "  label_tensor = torch.Tensor(labels)\n",
        "#   print(input_tensor.shape, concat_tensor.shape)\n",
        "  return input_tensor, label_tensor \n",
        "  \n",
        "\n",
        "train_loader = DataLoader(dataset, batch_size=16, shuffle=True, collate_fn=custom_collate_fn, drop_last=True)\n",
        "batch = next(iter(train_loader))\n",
        "batch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3c127044",
      "metadata": {
        "id": "3c127044",
        "outputId": "f1211ff7-3d3f-4608-e537-5e7dccc034ae"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(204560, 204567)"
            ]
          },
          "execution_count": 40,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(train_loader) * train_loader.batch_size, len(train_loader.dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b9264472",
      "metadata": {
        "id": "b9264472",
        "outputId": "a5eb9d93-3faf-40fc-91f0-01b13cf28999"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "204560"
            ]
          },
          "execution_count": 41,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "204567//16 * 16"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d29a6426",
      "metadata": {
        "id": "d29a6426",
        "outputId": "c3ebed2e-2cf4-4ccf-f226-975929337f4c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'\\nVanilla Gradient Descent\\n\\nweights -= weights.grad * lr\\n\\n'"
            ]
          },
          "execution_count": 42,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "'''\n",
        "Vanilla Gradient Descent\n",
        "\n",
        "weights -= weights.grad * lr\n",
        "\n",
        "'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "96791a45",
      "metadata": {
        "id": "96791a45"
      },
      "outputs": [],
      "source": [
        "from tqdm import tqdm\n",
        "import itertools \n",
        "model = NERModel()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
        "train_loader = DataLoader(dataset, batch_size=64, shuffle=False, collate_fn=custom_collate_fn, drop_last=True)\n",
        "\n",
        "loss_record = []\n",
        "# num_epochs = 5\n",
        "num_iteration = 0\n",
        "target_num_iteration = 10000\n",
        "\n",
        "# for epoch in tqdm(range(num_epochs)):\n",
        "for batch in itertools.cycle(train_loader):\n",
        "  input_tensor, label = batch # input_tensor = batch[0] // label = batch[1]\n",
        "  prediction = model(input_tensor)\n",
        "  loss = loss_fn(prediction, label.unsqueeze(1)) # Calculate loss\n",
        "  loss.backward() # Backpropagate the loss to get the gradient\n",
        "  optimizer.step() # Update the parameters\n",
        "  optimizer.zero_grad() # Reset the gradient of the parameters\n",
        "  loss_record.append(loss.item())\n",
        "  num_iteration += 1 \n",
        "  if num_iteration > target_num_iteration:\n",
        "    break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b411593b",
      "metadata": {
        "scrolled": false,
        "id": "b411593b",
        "outputId": "c29ac6a6-3d7a-473a-c4b9-e8c6c0a36c0c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7f2a96ad58e0>]"
            ]
          },
          "execution_count": 44,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD4CAYAAAD8Zh1EAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAAAlsUlEQVR4nO3deZwcdZ3/8dcnCRHFAzFRWYIGNR5xPYARQXQXBTXgPsi6eBBXFBfNT3fZxWV3NcoprsohLCrhCMgthBg5IuSAkIQAOSfkPpncE0Jmcp+TzGQ+vz+6etLT00d1d/X0dPX7+Xjkke6q71R9q6v7U9/61vcwd0dERKpfr0pnQEREoqGALiISEwroIiIxoYAuIhITCugiIjHRp1I77tevnw8cOLBSuxcRqUrz5s3b6u79M62rWEAfOHAg9fX1ldq9iEhVMrP12dapykVEJCYU0EVEYkIBXUQkJhTQRURiIm9AN7N7zazJzJbkSHOWmS0ws6Vm9kK0WRQRkTDClNDvB4ZkW2lmxwK3A+e7+0eBr0eSMxERKUjegO7u04HtOZJ8C3jc3TcE6ZsiypuIiBQgijr0DwJvN7NpZjbPzL6TLaGZDTezejOrb25ujmDXksmExZvZtvdgpbMhIt0sioDeBzgV+ArwZeAqM/tgpoTuPsrd69y9rn//jB2dpETb9x3iR396hUseUKctkVoTRU/RRmCbu+8D9pnZdOATwKoIti0FajvcDsCmnQcqnBMR6W5RlNCfAj5rZn3M7E3Ap4HlEWxXREQKkLeEbmaPAmcB/cysEbgGOArA3e909+VmNhFYBLQD97h71iaOIiJSHnkDursPC5HmJuCmSHIkIiJFUU9REZGYUEAXEYkJBXQRkZhQQBcRiQkFdBGRmFBAFxGJCQV0EZGYUECPKfdK50BEupsCetxYpTMgIpWigC4iEhMK6CIiMaGALiISEwroIiIxoYAuIhITCugiIjGhgC4iEhN5A7qZ3WtmTWaWcxYiM/uUmbWZ2deiy56IiIQVpoR+PzAkVwIz6w3cADwbQZ5ERKQIeQO6u08HtudJ9u/AX4CmKDIlIiKFK7kO3cxOAL4K3BEi7XAzqzez+ubm5lJ3LTlpMBeRWhPFQ9FbgZ+6e3u+hO4+yt3r3L2uf//+EexaRESS+kSwjTpgtJkB9APOM7M2d38ygm1L0TRKl0itKTmgu/tJyddmdj/wtIK5iEj3yxvQzexR4Cygn5k1AtcARwG4+51lzZ2IiISWN6C7+7CwG3P3i0vKjYiIFE09RUVEYkIBXUQkJhTQRURiQgFdRCQmFNBFRGJCAV1EJCYU0GNLY7mI1BoF9JgxdfkXqVkK6CIiMaGALiISEwroIiIxoYAuIhITCugiIjGhgC4iEhMK6CIiMaGALiISE3kDupnda2ZNZrYky/p/NrNFZrbYzGaY2Seiz6aIiOQTpoR+PzAkx/q1wN+7+8eAXwKjIsiXiIgUKMwUdNPNbGCO9TNS3s4CBkSQLymRaygXkZoTdR36JcCEbCvNbLiZ1ZtZfXNzc8S7FgDTUC4iNSuygG5mnycR0H+aLY27j3L3Onev69+/f1S7FhERQlS5hGFmHwfuAc51921RbFOKo6oWkdpVcgndzN4DPA5c5O6rSs+SREFVLyK1J28J3cweBc4C+plZI3ANcBSAu98JXA28A7jdElGkzd3rypVhERHJLEwrl2F51n8f+H5kORIRkaKop6iISEwooIuIxIQCuohITCigi4jEhAK6iEhMKKDHlDoYidQeBfSYUYcikdqlgC4iEhMK6FVg1ZY9NDTtqXQ2RKSHi2RwLimvL/3fdADWXf+VCudERHoyldBFRGJCAV1EJCYU0EVEYkIBXUQkJhTQRURiQgFdRCQm8gZ0M7vXzJrMbEmW9WZmvzezBjNbZGanRJ9NERHJJ0wJ/X5gSI715wKDgn/DgTtKz5aUSkO5iNSevAHd3acD23MkGQo86AmzgGPN7PioMiiF0VAuIrUrijr0E4CNKe8bg2VdmNlwM6s3s/rm5uYIdi0iIknd+lDU3Ue5e5271/Xv3787dy0iEntRBPRNwIkp7wcEy0REpBtFEdDHAd8JWrucDuxy980RbFeKoIehPcOCjTtZsmlXpbMhNSbvaItm9ihwFtDPzBqBa4CjANz9TmA8cB7QAOwHvleuzEp4ejhaWf848mVAI2RK98ob0N19WJ71DvxbZDkSEZGiqKeoiEhMKKCLiMSEArqISEwooIuIxIQCuohITCigx5Tao4vUHgX0mFH7c5HapYAuIhITCugiIjGhgC4iEhMK6CIiMaGALiISEwroIiIxoYAuIhITCugiIjERKqCb2RAzW2lmDWY2IsP695jZVDObb2aLzOy86LMarZFTG3hyvmbKE5H4yBvQzaw3MBI4FxgMDDOzwWnJrgTGuPvJwIXA7VFnNGo3TVrJjx9bUOlsiEiZzFi9lcsfW0BiDp7aEKaEfhrQ4O5r3P0QMBoYmpbGgbcGr98GvBZdFqUYtfQlFsnkW3fP5vEauwvPOwUdcAKwMeV9I/DptDTXAs+a2b8DxwDnRJI7KZiZRnMRqVVRPRQdBtzv7gNITBj9kJl12baZDTezejOrb25ujmjXIiIC4QL6JuDElPcDgmWpLgHGALj7TOBooF/6htx9lLvXuXtd//79i8uxiIhkFCagzwUGmdlJZtaXxEPPcWlpNgBnA5jZR0gEdBXBRUS6Ud6A7u5twKXAJGA5idYsS83sOjM7P0j2X8APzGwh8ChwseupnIhItwrzUBR3Hw+MT1t2dcrrZcCZ0WZNiqHrqEhn7lArbQXUUzSm1NpFal0t/gQU0EVEYkIBXUQkJhTQRURiouoC+tSVTZx98zTWbd1X6ayIiPQoVRfQ9x1sY3XzPg4dbq90Vno0tXYRSailX0LVBXQj8eha8SoztW4RqV3VF9AVr0REMqq6gJ7kPfBGat767Yyd11jpbIhIjQrVU7QnSRbQe2KVywV3zATga6cOqHBORKQWVV0JPVnl0hMDuohIJVVdQE+W0XtilYuI9Dy11OKr6gK6HoqKSBi1GCqqLqAn1dBFV0QklKoL6LV41RURCaP6ArqpY5GISCahArqZDTGzlWbWYGYjsqT5hpktM7OlZvZItNlM2U+5NiwiUuXytkM3s97ASOCLQCMw18zGBbMUJdMMAn4GnOnuO8zsneXKcJJaueSmT0dqXS3+BsKU0E8DGtx9jbsfAkYDQ9PS/AAY6e47ANy9KdpsHqF26LnpDkaks1oKFWEC+gnAxpT3jcGyVB8EPmhmL5vZLDMbkmlDZjbczOrNrL65ubmoDHcE9KL+WkRqRS0WbqJ6KNoHGAScBQwD7jazY9MTufsod69z97r+/fsXtSOrydMkIpJfmIC+CTgx5f2AYFmqRmCcu7e6+1pgFYkAXza11PtLRCSMMAF9LjDIzE4ys77AhcC4tDRPkiidY2b9SFTBrIkumylU5SIiklHegO7ubcClwCRgOTDG3Zea2XVmdn6QbBKwzcyWAVOB/3H3beXIcE8ebVFEpJJCDZ/r7uOB8WnLrk557cDlwb+y0ow8uek6J9JZLRX+qq6naNLCjTsrnYUeTZc9qXW1WPiruoCePEXXPb0sZzoRkVpTfQG99i66IiKhVF9AV2VCRsMfrOeHD82rdDZEpIKqL6Arnmf07LItTFz6esf7GnoOJJJRLfZVqbqALrnpeifSWS0N5Fd1AV0BS0TCUCuXalB750hEJJSqC+h6KCoiklnVBfRadvu0Bq77q9rfi0hmVRfQ41gt1nq4nfb2/A9ubpy4kntfXtsNORKRalR9Ab3SGSiDQVdM4OdPLK50NkRiqZZaL1ZfQE8ros/fsIN9B9uyph87r5EXVhU3O1J3Gj13Y/5Ekpe7s3H7/kpnQ3qAOBb+8qm6gJ5qdfNevnr7DP7tkVeypvnvPy/ku/fO6cZcSSXd/eIaPnfjVJZv3l3prIh0u6oL6KkF9N+MXwHAkk27KpQb6WnmrN0BoFK61KTqC+gprycv31KxfEhmq5v3snXvwUpnQ6QmhQroZjbEzFaaWYOZjciR7gIzczOriy6L6fso15bjpVIPgs6++QU+d8PUyuw8RQ09BxPpkDegm1lvYCRwLjAYGGZmgzOkewtwGTA76kym7aksW7123FIGjnimLNvuTj3hgneg9XDF9t0Tjl96hlq8qIcpoZ8GNLj7Gnc/BIwGhmZI90vgBqAlwvx1m/tnrKt0FkREShImoJ8ApLapawyWdTCzU4AT3T1nEdfMhptZvZnVNzcX15QwcwmsOoplSzbt4saJKyqdDSnC04teY8it02tySNZqVR1RIVolPxQ1s17ALcB/5Uvr7qPcvc7d6/r371/c/jJvuahthbV+2z4eiKAE/48jX+b2aatpO9xeeqaqyHPLtvCTsQu7dZ9Rx90fj17Aitf30BaiR69IpYQJ6JuAE1PeDwiWJb0F+FtgmpmtA04HxpXrwWglhsT8xl0zuWbcUvYfyt6BKYz2Gi3d/eDBesbUN1Y6GzVj864DmkS9RoUJ6HOBQWZ2kpn1BS4ExiVXuvsud+/n7gPdfSAwCzjf3evLkuMK2H2gtEDe02zYtp+PXTuJDdvi21a7XNf9argmn/GbKQwd+XKlsyEVkDegu3sbcCkwCVgOjHH3pWZ2nZmdX+4MpjtwqHItKKrhxxzG2Fca2dPSxuPzK1tq3newrWwdgKI+V2o9I9WgT5hE7j4eGJ+27Oosac8qPVvZVaLaIqofs5mB95wJsSp9gfrmqJks2bSbddd/JbJtKu5Kukp/z7tTVfcUzbe0khqa9vD4K91fAs705Z26oont+w51vO8pn9aSTRpvRcqnFu+qqi6gRx2Nzvvdi6HTFnKhP+eW6Vw+JnPLjlwlBnePpBVM8su8/1Ab37t/LhffpwHKROKu6gJ65inonJbWw0W1QlnWjaPyHQ6avOWqdPm/ya/ygSsmlNyiJinZzG5t874u6+J9J1qeo+s5FWYiXVVfQM9SQv/M9VMYfPWk8u67rFtPeHTOBgD2tpQW0JN3AbVUfyhS66ovoGdYtvdgW0cdcZip3HLJ1ROwmC1fP2FFlzyFDbKTl22JbnyZmqtP7P4DXvn6Hm6dvKrb9yuZ1WJhpvoCeoYiekvrkTrn26Y2lLT9TF+CfKHB3dm860DGdXe+sJoFjTsLzwdHSuuRcNix7xCf/vXkbq1mqpxof82Zq/o6u+COGdw6+dWKNq2VrmqpmixUs8WeJN+T60WNicku7nxhNXPWbi94+7lOfbbS+z0vruVX45fn+Lvw+y9nufKlhq1s2X2Q55YlxpFf3bSX9nanV6/4FN/L3bIh17lsDR5m12Lrip6oFs9D9ZXQ86ZI/OKun7CCKSuaCt5+pqC9L0+Ja8bqrQXuI8e6LK8LtetAa+cFGT64ZxZv5o4XVpewl8L05FmEDrW1c7AtmpJ1Ld7qS89QfQG93CWw8m4+2EdlfvGZPrv5G3aG/vvlm3dzz4trCtrns0tf73j9uRu7b+KLQoPqZ2+YwoeunFjSPmuxRCg9S9UF9HI/7Oqu0lVL62EGjniGu6d3DpCRH13K8WSqB25o2sM375oZqt733N+9yP8+k6haen1XC1c9uSRvm/nhD80rLL8lClPXnUnTHk2bJ9WvCgN6eRVTei70L9xh5/5Elcg9L2Uu8XbXhWXdtv3MXrudOesKe97ws8cX8dCs9bzYUFh1U9UqQznikdkbaNaFRCJUdQG93M/vuiOQ5tpFpW7bC524oacOC568IG/Z3cKCjTsZOOIZVr6+J7rtR3TcG7bt5+dPLOZTv5oczQZFqMKAnm889HIG5GybjioGH273TvmPcnYco7bqeK/96zLGL94MwLSV2R+Or27ey/ptXXvRliLfXd7M1dt4csGmnGkkOrX0kLrqmi0ufW1XWbffLSX0LDspppllVHa3tDF33XY+NfA4AJr2tNCnVy+OO6Zvzr8rtSNX1DLVoefK4dk3v1DWfWcy7O5Zke1Tskucj571/Sy3qiuh7z9Y3k4bUdShT1yyuaD0Sb/469KC912IXOHmPx6dz9fvPPJw9LRfPc8pv3wuY9qrnlzCrDXbAPjpXxZFnc3IlOOGpJwtlNyd55ZtKWhwtr0H23rcRVUqp+oCepgfVClf8ChK6MW0fwdY8fqeyFtbPFHgJBaHQ3wAD81az8G2RNDZuvdQntSVF8U5LfbiUEi12eTlTfzgwXrumBaub8D2fYf422sm8Ycp4XpHNzTtYeKS1/MnrHJR9SeoRqECupkNMbOVZtZgZiMyrL/czJaZ2SIze97M3ht9VhPe1Dd3LZED33+w+NnvPnrNJB6bG67L/WNzN7Bp54EuP/Z8U9a5578wFVsS3JM2qNe1f11W1HaqVanPCQaOeCZn1Vc5q+S27k1czDftzDyMRLb0Ty96LVT6c26Zzg8f7t5mpJBo4x/2N1WqJZt28aErJzJ52Zaa6vKflDegm1lvYCRwLjAYGGZmg9OSzQfq3P3jwFjgxqgzmnTG+9+RN02hJeT0Ev1vn808wFLqj3lPSys//ctivn3P7C7pJi7NUwoK8T2bvLypqK/j3910pPPOa2mBoac+FB18dWkdeqJWaOepdJ0fbBf3d1F6/JVGBl0xPn/CMmnccYCf/mVxt+xrfjA59tQcD8LzmbB4Mw1NpbWMmr1mGwNHPMOW3S0lbadQYUropwEN7r7G3Q8Bo4GhqQncfaq7J/t1zwIGRJvNI8oRk8KWiFK1B9WcW/ceLCrw5nuANn1Vc871O/YdoqU1963lZ66fcmR/ZhTz6d3/8tqC/6ZQ+8s1mFWGw91/qI2fjF3Izv3Zq4oc2N3SyqG2wiYayXXB/MZdM7lw1MyM69LPY74L78Oz1nPRH7sWJLK5fMxCWg/XVmnVoeOYl2zK3pCipfVwl/P8oz+9wjm3TC9p/w/OWg90f0OHMAH9BGBjyvvGYFk2lwATMq0ws+FmVm9m9c3NuQNWNvmaLRajqC7pJWQjzK1gvs2f/Mvn+McyzOyevt/urLJpaT3MbVNeLTiQ5pP6eT82dyNj6hu5dfKr2dM7fPzaZ7nkgbld1r2Q50Lbdd8Jc9ZuZ9aazD/uobcVdh6vfHIJL74aXYeufAWDapLpd5OrieiHr5rIF26eVtI+L7l/Ltc8tSTjuu6+jEb6UNTMvg3UATdlWu/uo9y9zt3r+vfvH+WuQ/v0rydnLSklFXqb3GUgrBB/c6QDTOaHoGGuWysK6DBTaB4r4cNXTeS3z67i4aB0k+qnYxcVNF1gKVZuSQwvnClo/uufXil4e8m67uz720ND056O0Rq709QVTXz4qoksCKoq4ijf77lxR+F36KmeX9HEAzO7fmcrIUxA3wScmPJ+QLCsEzM7B7gCON/dy9afOV+ca89z9rbsPpi1pJTPhaNm0bij84iBew+2hRrgKtdtX3dp3lNcfV5L62GeX74l6/r0z6RUBzKUGB+r3xjJOO43TVqZN83G7aX9wDuNmOnOGb95Pu/fnHPLdK4Zl2y22n0PO5J3HPPW7+i2fab71TPLQk/kUkz1aDnsaWnlt5NWVuQinEuYgD4XGGRmJ5lZX+BCYFxqAjM7GbiLRDAv/mlECPlKrtNWFleVE8byzbu5LWgiVkjNT/Oeg/zDH17qeH+g9XDervOGRf6QLFOgTPfKhq4/7B88WM8lD2RvOfTj0QsKzsvUHA+ui212+sqGHZ2qDzI9p0jW1xfaCzf1fC/KMmFJtq9EsfXXTXta8j5LKVXyuKLslQyJDoBhq3LufjHzc5qZq7fxVEp1yYzVWznz+imdlmVT6OH80+2FVXvdNGklt01tYNyCzC2MKtX+IG9Ad/c24FJgErAcGOPuS83sOjM7P0h2E/Bm4M9mtsDMxmXZXMmKHU2vMEe+Delf9OTbXLlID/bpHYY+c/0ULn9sQc4c9OoFGyIeP/zX41fkTXPRH+d0WZavvjZM2/VUM1Zv5Xv3d62fTiomnr++q4V/un0GUzNc0KO+MJ5/28u8vivc3U4pu77gjhl8596u56NcorqL3Lr3IF/5/UuM+Muigi4U6WmH3T2Ly1IKCys2J6oYc90RZypohcnCKwUMIw1Hnju0tfesEnqorv/uPh4Yn7bs6pTX50Scr8jt3H+IY9+Uuxt7UmpnmfQvQ5jgld7hODnfaarZIZ5+r90a7RgjPcW2DJ2RUpuZ5as2y2Tvwa7PCJI/7k07D3C43eldwshu6QWJxP6OLnp7YZRa9VOIsfMa+d9nlvO9Mwfy8QFv46snF99QLTnBeaFB0r3nNq0tVtR3PvlUXU/RYk/4J697jtlBd/Uwlgf1temnIzl9Wy69IvhWds+dSHTWNO8NXQ+a6Sv+vfvm5lyfzU2TVnDzs5nrxecH1UePzN7A70qcvLlry6Rw56eY33MxX5+N2/czpn5j/oTp+wqOI/mA/b6X1/Gfjy0sPAOZtl3gcRw63M6a5r0RbS/lLrvI+6Tt+w4V3ZigHK3xwqi6gF6KhQVM1nxu0KLi5bTxvpMnONcJS19V1Ncp5PfhCzdPK7gpXT6rthTeqaI+5EO1bJNpF2vk1NVZu76nPvx+qWFrpzrdcpabUktld5fYSSmsr94+g5+MXVTwQ8NKzsGa7oonlvCFm1/IeEdbinVb97PvYO7e25mc8svn+MQvns24rqeO4Fh1Af1vjn1jt+4vUx3mvoNt7MjxpUsvXUfdrjrVmuZ9XPVk5jawxfpWgaMBFjKN3dfvnFmRew+HrCX5MHLdMbV1TA7dNU2YVjX5JFtSzFqzjWvHZR7ALdk08syUzmT57Nx/qEeNezIzmJt3b0vhwTeXOeu2891ufBZRSVU3fG4p9aCFXlWzPfj6ws3TsrYfh8StY6kKOcqoS1nFPJScty5cCb1xx4GSSsft7U6vIr4D8zfsLOjCk+Tu/PbZlV1aCO06kLigP7VgE5eNXsBt3zq54G1nk350g66YwKiLTs06nd/GIpuNfvK6zKNpRmX9ts75em3nAXa3tDLonW9h+qvNfP5D7+y0Pvm92LTzAG9741FF7TPbhTfsHWQuVz65mIdnbWDd9V/psXX9VRfQS1FoIMnWPCpXMI9KpergivVYEfW3WeW48t794hr+39+/v+RdtB72UHdO9et3MHJq19EPL7hjJv/z5Q91lMAvfWQ+b35D4udUjrvxTNWFbUFzyJbW7mlp4e4cbnf69M59Y5/t+JNDUbz16D7sbmnjvos/xec//E7MOp/yYXfPot+bszdgCPOgMVOSl17dymcH9cv7t9k8PCvcAGNj5zXy14XhBkyLWtVVuZTi+gn5m+2l+k2B6aOUK5ynj+ORXhIqVdR1mOmuH7+86L/9zYQVkTSve3TOBj54ZcYRKjq54onsg0oVU51S7OxImUqe3T1y4kOz1vOBKybQVMCAU5lC7+6gSqU5rQft5pQ74kzDMpdaxJmco3NcLtNWNoW6iLQebmfk1Ab++8+ZHyq7O0Nunc64Mgb7mgro1STXKG1RjuNRLpt3HWD0nMwlmtfytOFen6f9/QV3zCg6X4VqK6JTUK7f/i3P5W9tM3pu17udTDdsxfZTuH1auPHT0z0xP3HHml7Fs2V3C88sSkzq8sKq5tC9Tpv3HAw9suXyzbs7NeNdvnk3C7tpuIKL75vL5WPyt/wZPXdjl4t86neh3ROtiS4bPT/qLHaoqSqXahKmnXpP9s27ZhUdcJ5a8Bpf+PA7GfrJxBhw6TNAdWcDg0L2FaYEGSbN4Xbv0ls27CQWYdw4cSX/etYH8uah9XA7Rx/Vu2NZat6b9xykft12zv3Y8Xzr7lmsbt7H2R8Z0uXhY64+BYXc4ZybMo7PAzPXd4ydsu76r3RKd6Tna9dtJEvZrYfb+cVfl/IfZw8Kvf/kxSyXlnKNGloAldClLErt5XrZ6AVs33eIP9dv5JdP56+iKdfwsMV0DHk0y50JwN6QUyi+7+elj1/etKeFe18qbvjj9/98PB++amKnO8Xkcx13uPi+OfzoT6+wu6WV13Ym0hzO8DT9pYbS7yaj6pzzwMz1HdP8PTxrA6f9Kv8YO9nzVMzflL8oohK69FhPLdjELzIM33uorZ3Xdh5gTfORW/Cw07YVal0Bzyf2BG2dcz2rKbYetxilBKykl17dygWnJnqNJkvozpERCtvbnWSjo0yl8dQOY8XK12P2oj/Opmn3QSb95991LHt+RebP+Yonl3Dm+4t/MAqdRy7dVsTzpnLGdQV06bEyBfOkz6S1ty72YWOt+sPz2ceDT+XAwo07GZoy9v4VTyzuCGrudDQjTe+EF5V8Q0GkPlNKXnSyzXX77NItfOTdb8m4btveg50ezGYz9LaX+NTA44BE9VUujvPAjHW0tTvfOaNsM3N2UECXWFjYWPnhiavJzSEezgIZW2ys2nKke75zJIj+8OHCx4ovVeqk12HmVt269yBXPZW5c9a5v3sx1CTt67btz3jndscLXe8S29vpGBY5tcql2P4U+agOXUSK5l6ewJTqshwjk6Y23bz0kfkl1dmHCea5ZGrum9oh7X+fOfIs6JnFm7ukjYICuogUzYlmMLpcCmme+PSi8gTKYl2ZZViOvUWMLRNGVQb0Y99UXLdgEYnW0NteLntHtDgqZojoMKoyoC+4+kt87dTix2sWkWj0lCnhqk25WrqECuhmNsTMVppZg5mNyLD+DWb2WLB+tpkNjDynab780XeXexciImVRrpaLeQO6mfUGRgLnAoOBYWY2OC3ZJcAOd/8A8H/ADVFnNF2fMj+IEREpl007ynNnE6aEfhrQ4O5r3P0QMBoYmpZmKPBA8HoscLaVebjA1FHTRl10Kif1O6ZLmn/7fOmj8omIRO3ODE0coxCmHfoJQOpoQY3Ap7Olcfc2M9sFvAPo1IbIzIYDwwHe8573FJnlhKN696L+ynN469FH0bdPL744+F28smEnzy/f0jFGw9FH9eacj7yLLbsPcv+MtbzxqN5MXdnMml+fx5QVTXzixGOZs3Y7Y+o38sKqZn534Se5YcIK9rS0dfT6AzjvY+/mHce8gYdmrc+TJ8vZBf24Y/ryrrcezRcHv4slm3YxZUVT1rTpLvzUiXz79PfyD394qdPyYae9p0tX888N6sfnBvXj1+NX8PEBb2NRljbaF39mIMs272ZOiHFjellx46T3VG/q25v9PWDsDalND/zLaWXZruUbX8DMvgYMcffvB+8vAj7t7pempFkSpGkM3q8O0mRtFFpXV+f19fURHIKISO0ws3nuXpdpXZgql03AiSnvBwTLMqYxsz7A24DwMzKLiEjJwgT0ucAgMzvJzPoCFwLj0tKMA74bvP4aMMW7Y2gxERHpkLcOPagTvxSYBPQG7nX3pWZ2HVDv7uOAPwIPmVkDsJ1E0BcRkW4UanAudx8PjE9bdnXK6xbg69FmTUREClGVPUVFRKQrBXQRkZhQQBcRiQkFdBGRmMjbsahsOzZrBnJ3vcyuH2m9UGuAjrk26JhrQynH/F53759pRcUCeinMrD5bT6m40jHXBh1zbSjXMavKRUQkJhTQRURioloD+qhKZ6ACdMy1QcdcG8pyzFVZhy4iIl1VawldRETSKKCLiMRE1QX0fBNWVwszO9HMpprZMjNbamaXBcuPM7PnzOzV4P+3B8vNzH4fHPciMzslZVvfDdK/ambfzbbPnsLMepvZfDN7Onh/UjC5eEMw2XjfYHnWycfN7GfB8pVm9uUKHUooZnasmY01sxVmttzMzoj7eTaz/wy+10vM7FEzOzpu59nM7jWzpmCCn+SyyM6rmZ1qZouDv/m9WYhpPd29av6RGL53NfA+oC+wEBhc6XwVeSzHA6cEr98CrCIxCfeNwIhg+QjghuD1ecAEwIDTgdnB8uOANcH/bw9ev73Sx5fn2C8HHgGeDt6PAS4MXt8J/Ch4/a/AncHrC4HHgteDg3P/BuCk4DvRu9LHleN4HwC+H7zuCxwb5/NMYkrKtcAbU87vxXE7z8DfAacAS1KWRXZegTlBWgv+9ty8ear0h1LgB3gGMCnl/c+An1U6XxEd21PAF4GVwPHBsuOBlcHru4BhKelXBuuHAXelLO+Urqf9IzHj1fPAF4Cngy/rVqBP+jkmMQb/GcHrPkE6Sz/vqel62j8Ss3etJWiAkH7+4nieOTLH8HHBeXsa+HIczzMwMC2gR3Jeg3UrUpZ3SpftX7VVuWSasPqECuUlMsEt5snAbOBd7r45WPU68K7gdbZjr7bP5FbgJ0B78P4dwE53T87KnZr/TpOPA8nJx6vpmE8CmoH7gmqme8zsGGJ8nt19E/BbYAOwmcR5m0e8z3NSVOf1hOB1+vKcqi2gx46ZvRn4C/Bjd9+dus4Tl+bYtCs1s38Amtx9XqXz0o36kLgtv8PdTwb2kbgV7xDD8/x2YCiJi9nfAMcAQyqaqQqoxHmttoAeZsLqqmFmR5EI5n9y98eDxVvM7Phg/fFAU7A827FX02dyJnC+ma0DRpOodvkdcKwlJheHzvnPNvl4NR1zI9Do7rOD92NJBPg4n+dzgLXu3uzurcDjJM59nM9zUlTndVPwOn15TtUW0MNMWF0VgifWfwSWu/stKatSJ9z+Lom69eTy7wRPy08HdgW3dpOAL5nZ24OS0ZeCZT2Ou//M3Qe4+0AS526Ku/8zMJXE5OLQ9ZgzTT4+DrgwaB1xEjCIxAOkHsfdXwc2mtmHgkVnA8uI8XkmUdVyupm9KfieJ485tuc5RSTnNVi328xODz7D76RsK7tKP1Qo4iHEeSRahKwGrqh0fko4js+SuB1bBCwI/p1Hou7weeBVYDJwXJDegJHBcS8G6lK29S9AQ/Dve5U+tpDHfxZHWrm8j8QPtQH4M/CGYPnRwfuGYP37Uv7+iuCzWEmIp/8VPtZPAvXBuX6SRGuGWJ9n4BfACmAJ8BCJliqxOs/AoySeEbSSuBO7JMrzCtQFn99q4DbSHqxn+qeu/yIiMVFtVS4iIpKFArqISEwooIuIxIQCuohITCigi4jEhAK6iEhMKKCLiMTE/wfITtnSLRsdPAAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.plot(loss_record)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ec56b7cb",
      "metadata": {
        "id": "ec56b7cb"
      },
      "source": [
        "## Calculate Accuracy\n",
        "- first, with training data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8c062fc8",
      "metadata": {
        "id": "8c062fc8"
      },
      "outputs": [],
      "source": [
        "threshold = 0.5\n",
        "num_total_acc_pred = 0\n",
        "for batch in train_loader:\n",
        "  input_tensor, label = batch # input_tensor = batch[0] // label = batch[1]\n",
        "  prediction = model(input_tensor)\n",
        "  num_accurate_prediction = ((prediction[:,0] > threshold) == label ).sum()\n",
        "  num_total_acc_pred += num_accurate_prediction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e6146872",
      "metadata": {
        "id": "e6146872",
        "outputId": "eb7d2e6c-b985-4736-cfd0-d6772a6dabef"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor(0.9968)"
            ]
          },
          "execution_count": 86,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "num_total_acc_pred / len(train_loader.dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5966937c",
      "metadata": {
        "id": "5966937c"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "87166a45",
      "metadata": {
        "id": "87166a45",
        "outputId": "daeaf002-6b0e-4a2b-987f-215cf95b4637"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([64, 1])"
            ]
          },
          "execution_count": 81,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "prediction.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "24394355",
      "metadata": {
        "id": "24394355",
        "outputId": "5f8ad530-0bce-412c-ab59-5558544df6b2"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([    0.0025,     0.0000,     0.0000,     0.0000,     0.0000,     0.0000,\n",
              "            0.0000,     0.0000,     0.0000,     0.0002,     0.0000,     0.0000,\n",
              "            1.0000,     0.0000,     0.0000,     0.0000],\n",
              "       grad_fn=<SelectBackward0>)"
            ]
          },
          "execution_count": 73,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# torch.set_printoptions(sci_mode=False)\n",
        "threshold = 0.5\n",
        "short_pred = prediction[:16, 0]\n",
        "short_pred"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bc29b120",
      "metadata": {
        "id": "bc29b120",
        "outputId": "f16efbd9-c4a3-4d71-db71-5bef0486571f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.])"
            ]
          },
          "execution_count": 77,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "(short_pred > threshold).float()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7cfa7145",
      "metadata": {
        "id": "7cfa7145",
        "outputId": "1d6731a1-abe2-44b2-bce2-7703aa6abd84"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.])"
            ]
          },
          "execution_count": 76,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "label[:16]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "35ee9bf5",
      "metadata": {
        "id": "35ee9bf5",
        "outputId": "7f93edb8-eeef-4532-a912-c0958714aa90"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
              "        True, True, True, True])"
            ]
          },
          "execution_count": 79,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "is_accurate_pred = (short_pred > threshold).float() == label[:16]\n",
        "is_accurate_pred"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "adc399ea",
      "metadata": {
        "id": "adc399ea",
        "outputId": "134d30c1-eb99-4553-8b41-1b1125e87001"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor(16)"
            ]
          },
          "execution_count": 80,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# count the number of correct prediction\n",
        "is_accurate_pred.sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6939fc81",
      "metadata": {
        "id": "6939fc81"
      },
      "outputs": [],
      "source": [
        "testset = WindowWordDataset('test.txt')\n",
        "test_loader = DataLoader(testset, batch_size=64, shuffle=False, collate_fn=custom_collate_fn, drop_last=False)\n",
        "threshold = 0.5\n",
        "num_total_acc_pred = 0\n",
        "for batch in test_loader:\n",
        "  input_tensor, label = batch # input_tensor = batch[0] // label = batch[1]\n",
        "  prediction = model(input_tensor)\n",
        "  num_accurate_prediction = ((prediction[:,0] > threshold) == label ).sum()\n",
        "  num_total_acc_pred += num_accurate_prediction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2747e260",
      "metadata": {
        "id": "2747e260",
        "outputId": "7d21c566-372b-439e-c913-6cd2021088dd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(tensor([[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
            "        [ 0.0000,  0.0000,  0.0000,  ..., -0.1950,  0.2041,  0.3530],\n",
            "        [ 0.0000,  0.0000,  0.0000,  ..., -0.2705, -0.1292, -0.0133],\n",
            "        ...,\n",
            "        [ 0.0644,  0.2420,  0.2520,  ..., -0.4491,  0.1715, -0.0750],\n",
            "        [ 0.0121,  0.0925, -0.3330,  ..., -0.2737, -0.0990, -0.7888],\n",
            "        [-0.0677,  0.0513, -0.4817,  ..., -0.5074, -0.2050, -0.0687]]), tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]))\n"
          ]
        }
      ],
      "source": [
        "for batch in train_loader:\n",
        "  print(batch)\n",
        "  break\n",
        "\n",
        "# batch = next(iter(train_loader))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f0852b1a",
      "metadata": {
        "scrolled": true,
        "id": "f0852b1a",
        "outputId": "0d3c36e6-066c-4db8-8411-3d063fe94906"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(tensor([[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
              "         [ 0.0000,  0.0000,  0.0000,  ..., -0.1950,  0.2041,  0.3530],\n",
              "         [ 0.0000,  0.0000,  0.0000,  ..., -0.2705, -0.1292, -0.0133],\n",
              "         ...,\n",
              "         [ 0.0644,  0.2420,  0.2520,  ..., -0.4491,  0.1715, -0.0750],\n",
              "         [ 0.0121,  0.0925, -0.3330,  ..., -0.2737, -0.0990, -0.7888],\n",
              "         [-0.0677,  0.0513, -0.4817,  ..., -0.5074, -0.2050, -0.0687]]),\n",
              " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
              "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "         0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]))"
            ]
          },
          "execution_count": 46,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "batch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a1fadde1",
      "metadata": {
        "id": "a1fadde1"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "id": "68dcf4f2",
      "metadata": {
        "id": "68dcf4f2"
      },
      "source": [
        "# Toy cases"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bee8fd2a",
      "metadata": {
        "id": "bee8fd2a",
        "outputId": "d6a9f8d7-eb80-4af3-84cb-dc6e8e521ef9"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor(-8.)"
            ]
          },
          "execution_count": 55,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "first_word_vec = torch.Tensor([0.3, -0.2, 0.4])\n",
        "third_word_vec = torch.Tensor([-1, 0, 2])\n",
        "second_word_vec = torch.Tensor([-2, -1, 1])\n",
        "fourth_word_vec = torch.Tensor([-2, 1, 5])\n",
        "\n",
        "weight_for_first_wrd = torch.Tensor([0, 2, 1])\n",
        "weight_for_third_wrd = torch.Tensor([1, 2,-1])\n",
        "weight_for_second_wrd = torch.Tensor([-1, 3, -2])\n",
        "\n",
        "weight_for_fourth_wrd = torch.rand(3) \n",
        "\n",
        "\n",
        "(first_word_vec * weight_for_first_wrd).sum(), (second_word_vec * weight_for_second_wrd).sum(), (third_word_vec * weight_for_third_wrd).sum()\n",
        "activation_of_this_neuron = (first_word_vec * weight_for_first_wrd).sum() + (second_word_vec * weight_for_second_wrd).sum() + (third_word_vec * weight_for_third_wrd).sum()\n",
        "\n",
        "activation_of_this_neuron"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cf9256d5",
      "metadata": {
        "id": "cf9256d5",
        "outputId": "61cb053c-d24d-44cd-aa95-1a86ae6725d0"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor(-8.)"
            ]
          },
          "execution_count": 61,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "concatenated_vec = torch.cat([first_word_vec, second_word_vec, third_word_vec])\n",
        "concatenated_vec\n",
        "\n",
        "concatenated_weights = torch.cat([weight_for_first_wrd, weight_for_second_wrd, weight_for_third_wrd])\n",
        "\n",
        "(concatenated_vec * concatenated_weights).sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a5e18f67",
      "metadata": {
        "id": "a5e18f67",
        "outputId": "d418f61d-97e6-4cad-b65e-aa81ecd1e46c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([ 0.,  2.,  1.,  1.,  2., -1., -1.,  3., -2.])"
            ]
          },
          "execution_count": 62,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "concatenated_weights"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3c383d02",
      "metadata": {
        "id": "3c383d02",
        "outputId": "f283ab7d-52fb-416d-ee11-70717e3931ea"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor(0.9881)"
            ]
          },
          "execution_count": 93,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "num_total_acc_pred / len(test_loader.dataset)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6dce0efd",
      "metadata": {
        "id": "6dce0efd"
      },
      "source": [
        "## 5. Make Inference"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3fcf2a6c",
      "metadata": {
        "id": "3fcf2a6c"
      },
      "outputs": [],
      "source": [
        ""
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    },
    "colab": {
      "name": "“2. Named Entity Recognition Livecoding.ipynb”的副本",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}