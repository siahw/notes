{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/siahw/notes/blob/main/%E2%80%9C2_Named_Entity_Recognition_Livecoding_ipynb%E2%80%9D%E7%9A%84%E5%89%AF%E6%9C%AC.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "45a2da87",
      "metadata": {
        "id": "45a2da87"
      },
      "source": [
        "# Named Entity Recognition\n",
        "- For a given word and its context window, estimate whether the given word is "
      ]
    },
    {
      "cell_type": "markdown",
      "id": "11619f5d",
      "metadata": {
        "id": "11619f5d"
      },
      "source": [
        "# 1. Download dataset\n",
        "- CoNLL2003 "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "10a4faa3",
      "metadata": {
        "id": "10a4faa3"
      },
      "outputs": [],
      "source": [
        "!wget https://data.deepai.org/conll2003.zip # Download dataset\n",
        "!unzip conll2003.zip # Unzip dataset zip"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7643dde5",
      "metadata": {
        "id": "7643dde5"
      },
      "source": [
        "## 2. Preprocess Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d31874b2",
      "metadata": {
        "id": "d31874b2",
        "outputId": "0ca36f0b-e3d9-4738-8654-90696c72973d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[\"'s POS B-NP O\",\n",
              " 'representative NN I-NP O',\n",
              " 'to TO B-PP O',\n",
              " 'the DT B-NP O',\n",
              " 'European NNP I-NP B-ORG',\n",
              " 'Union NNP I-NP I-ORG',\n",
              " \"'s POS B-NP O\",\n",
              " 'veterinary JJ I-NP O',\n",
              " 'committee NN I-NP O',\n",
              " 'Werner NNP I-NP B-PER',\n",
              " 'Zwingmann NNP I-NP I-PER',\n",
              " 'said VBD B-VP O',\n",
              " 'on IN B-PP O',\n",
              " 'Wednesday NNP B-NP O',\n",
              " 'consumers NNS I-NP O',\n",
              " 'should MD B-VP O',\n",
              " 'buy VB I-VP O',\n",
              " 'sheepmeat NN B-NP O',\n",
              " 'from IN B-PP O',\n",
              " 'countries NNS B-NP O',\n",
              " 'other JJ B-ADJP O',\n",
              " 'than IN B-PP O',\n",
              " 'Britain NNP B-NP B-LOC',\n",
              " 'until IN B-SBAR O',\n",
              " 'the DT B-NP O',\n",
              " 'scientific JJ I-NP O',\n",
              " 'advice NN I-NP O',\n",
              " 'was VBD B-VP O',\n",
              " 'clearer JJR B-ADJP O',\n",
              " '. . O O']"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "with open(\"train.txt\") as f:\n",
        "  string = ''.join(f.readlines())\n",
        "dataset = string.split('\\n')\n",
        "\n",
        "dataset[50:80]  #I-PER means continuous for the previous class is related to this current word"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "49e7f34b",
      "metadata": {
        "scrolled": true,
        "id": "49e7f34b",
        "outputId": "aae13885-8127-4889-8713-c19e8ad3e9ba"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[['-DOCSTART- -X- -X- O'],\n",
              " ['EU NNP B-NP B-ORG',\n",
              "  'rejects VBZ B-VP O',\n",
              "  'German JJ B-NP B-MISC',\n",
              "  'call NN I-NP O',\n",
              "  'to TO B-VP O',\n",
              "  'boycott VB I-VP O',\n",
              "  'British JJ B-NP B-MISC',\n",
              "  'lamb NN I-NP O',\n",
              "  '. . O O'],\n",
              " ['Peter NNP B-NP B-PER', 'Blackburn NNP I-NP I-PER'],\n",
              " ['BRUSSELS NNP B-NP B-LOC', '1996-08-22 CD I-NP O'],\n",
              " ['The DT B-NP O',\n",
              "  'European NNP I-NP B-ORG',\n",
              "  'Commission NNP I-NP I-ORG',\n",
              "  'said VBD B-VP O',\n",
              "  'on IN B-PP O',\n",
              "  'Thursday NNP B-NP O',\n",
              "  'it PRP B-NP O',\n",
              "  'disagreed VBD B-VP O',\n",
              "  'with IN B-PP O',\n",
              "  'German JJ B-NP B-MISC',\n",
              "  'advice NN I-NP O',\n",
              "  'to TO B-PP O',\n",
              "  'consumers NNS B-NP O',\n",
              "  'to TO B-VP O',\n",
              "  'shun VB I-VP O',\n",
              "  'British JJ B-NP B-MISC',\n",
              "  'lamb NN I-NP O',\n",
              "  'until IN B-SBAR O',\n",
              "  'scientists NNS B-NP O',\n",
              "  'determine VBP B-VP O',\n",
              "  'whether IN B-SBAR O',\n",
              "  'mad JJ B-NP O',\n",
              "  'cow NN I-NP O',\n",
              "  'disease NN I-NP O',\n",
              "  'can MD B-VP O',\n",
              "  'be VB I-VP O',\n",
              "  'transmitted VBN I-VP O',\n",
              "  'to TO B-PP O',\n",
              "  'sheep NN B-NP O',\n",
              "  '. . O O']]"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from itertools import groupby\n",
        "\n",
        "dataset_in_sentence = [list(group) for k, group in groupby(dataset, lambda x: x == \"\") if not k]\n",
        "dataset_in_sentence[:5]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "18c29a2a",
      "metadata": {
        "id": "18c29a2a"
      },
      "source": [
        "### 2.1 Make Data Loader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8a4d1fbc",
      "metadata": {
        "scrolled": true,
        "id": "8a4d1fbc",
        "outputId": "c52b4a8f-83b0-4108-de82-5e22577b8333"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['said', 'on', 'thursday', 'it', 'disagreed']"
            ]
          },
          "execution_count": 51,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "window_size = 2 \n",
        "sentence = dataset_in_sentence[4]\n",
        "word_idx = 5 #5th list of word\n",
        "center_word = sentence[2].split(' ')[0] #select the first word\n",
        "\n",
        "# from word_idx - window_length until word_idx + window_length\n",
        "def get_words_window(sentence, word_idx, window_size):\n",
        "  idx_range = range( max(word_idx-window_size, 0), min(word_idx+window_size+1, len(sentence)))\n",
        "  windowed_words = [sentence[idx].split(' ')[0].lower() for idx in idx_range]\n",
        "  \n",
        "  if word_idx < window_size:\n",
        "    windowed_words = ['PAD'] * (window_size-word_idx) + windowed_words\n",
        "  if word_idx + window_size >= len(sentence):\n",
        "    windowed_words += ['PAD'] * (word_idx + window_size -len(sentence)+1)\n",
        "  \n",
        "  return windowed_words\n",
        "\n",
        "get_words_window(sentence, word_idx, window_size)\n",
        "# center_word"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d1c52b6c",
      "metadata": {
        "id": "d1c52b6c"
      },
      "outputs": [],
      "source": [
        "import gensim.downloader\n",
        "\n",
        "wrd2vec = gensim.downloader.load(\"glove-wiki-gigaword-300\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b5a0f80d",
      "metadata": {
        "id": "b5a0f80d",
        "outputId": "ef2a727e-64db-42eb-eaed-d469966f7624"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['PAD', 'PAD', 'the', 'european', 'commission']\n",
            "the [ 0.04656    0.21318   -0.0074364 -0.45854   -0.035639   0.23643\n",
            " -0.28836    0.21521   -0.13486   -1.6413   ]\n",
            "european [ 0.37636   0.1245    0.13028   0.024309  0.50706   0.18205  -0.44874\n",
            "  0.35522   0.27065  -2.2199  ]\n",
            "commission [ 4.7286e-01 -3.9634e-01 -2.6584e-01  1.2371e-02 -2.5906e-01 -2.5823e-01\n",
            "  1.1492e-01 -1.4363e-01  2.0568e-03 -2.2627e+00]\n"
          ]
        }
      ],
      "source": [
        "word_idx = 0\n",
        "words_window = get_words_window(sentence, word_idx, window_size)\n",
        "print(words_window)\n",
        "for word in words_window:\n",
        "  if word in wrd2vec:\n",
        "    print(word , wrd2vec[word][:10])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5a6bd62c",
      "metadata": {
        "id": "5a6bd62c",
        "outputId": "9253eb10-5b24-4cae-e611-946d1c6805e9"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([1500])"
            ]
          },
          "execution_count": 63,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# concat vectors\n",
        "import torch\n",
        "\n",
        "concat_vector = []\n",
        "for word in words_window:\n",
        "  if word in wrd2vec:\n",
        "    concat_vector.append(torch.Tensor(wrd2vec[word]))\n",
        "  else:\n",
        "    zero_vector = torch.zeros(300) #300dimension\n",
        "    concat_vector.append(zero_vector)\n",
        "\n",
        "torch.cat(concat_vector).shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d5cc5ff0",
      "metadata": {
        "id": "d5cc5ff0",
        "outputId": "c8be5606-a038-4cfd-a886-3cf8ab426603"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(False)\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "\"\\n[300 300 300 300 300]\\n1500 \\n\\nconcat_tensor's 1200th dimension\\n= 0th dimension of the 4th word\\n\\nconcat_tensor's 50th dimension\\n= 50th dimension of the 0th word\\n\\nconcat_tensor's 350th dimension\\n= 50th dimension of the 1st word\\n\\n\\n\""
            ]
          },
          "execution_count": 76,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "concat_tensor = torch.cat(concat_vector)\n",
        "\n",
        "print(concat_tensor[650] == concat_vector[2][49]) \n",
        "'''\n",
        "[300 300 300 300 300] #5 300vectors\n",
        "1500 \n",
        "\n",
        "concat_tensor's 1200th dimension\n",
        "= 0th dimension of the 4th word because 300*4=12000\n",
        "\n",
        "concat_tensor's 50th dimension\n",
        "= 50th dimension of the 0th word becasue 0+50=50\n",
        "\n",
        "concat_tensor's 350th dimension\n",
        "= 50th dimension of the 1st word because 300+50=350\n",
        "\n",
        "\n",
        "'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e89c74c8",
      "metadata": {
        "id": "e89c74c8"
      },
      "outputs": [],
      "source": [
        "import torch.nn as nn #multilayer perception\n",
        "\n",
        "hidden_size = 128\n",
        "first_layer = nn.Linear(300*5, 128, bias=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d62884d5",
      "metadata": {
        "id": "d62884d5",
        "outputId": "e54cc24f-1633-47bb-d07a-996167778dc6"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([128, 1500])"
            ]
          },
          "execution_count": 83,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "first_layer.weight.shape #128 neurons, each neurons see 1500vectors"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6b2d23ea",
      "metadata": {
        "id": "6b2d23ea",
        "outputId": "ffc73a53-4a46-4cd7-e008-0958bdc719bd"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(torch.Size([1500]), torch.Size([128]))"
            ]
          },
          "execution_count": 88,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "hidden = first_layer(concat_tensor)\n",
        "concat_tensor.shape, hidden.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1772c2c6",
      "metadata": {
        "id": "1772c2c6",
        "outputId": "7e23cdb8-62b5-4ba3-dbc4-bf322959bd88"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([-0.1014, -0.0434,  0.1495,  0.0594, -0.1511, -0.0104, -0.0830, -0.0217,\n",
              "         0.0269,  0.1687,  0.2679,  0.0423,  0.1710, -0.0205, -0.1302, -0.3823,\n",
              "        -0.2216,  0.1646,  0.2188,  0.0234, -0.1152,  0.1256,  0.1081,  0.2385,\n",
              "         0.2288, -0.0017,  0.0467, -0.0243,  0.1805,  0.0397,  0.0331,  0.1226,\n",
              "         0.1068, -0.1220,  0.2065, -0.1513,  0.2422,  0.1978,  0.0621,  0.0944,\n",
              "         0.0589,  0.0851,  0.2401,  0.0359, -0.1163,  0.1025, -0.3653,  0.1052,\n",
              "         0.1608,  0.0969, -0.0260, -0.1708, -0.2358, -0.2242, -0.0224, -0.0895,\n",
              "         0.0413, -0.2420, -0.0761, -0.0006,  0.1911,  0.0721, -0.0274,  0.0084,\n",
              "         0.1376, -0.0117, -0.0238, -0.0739,  0.0417, -0.0189,  0.0175,  0.0612,\n",
              "         0.2436, -0.0954,  0.0930, -0.1291,  0.3059, -0.2236, -0.1336,  0.1935,\n",
              "         0.2372, -0.0942, -0.0061, -0.2416,  0.1701,  0.1200,  0.2148, -0.0873,\n",
              "        -0.0901, -0.1089, -0.1481, -0.0412,  0.2116, -0.0769, -0.1613, -0.1882,\n",
              "         0.1070, -0.1290, -0.0027, -0.0408, -0.2308, -0.1159,  0.3301, -0.0560,\n",
              "        -0.2788, -0.2808, -0.2233, -0.0059, -0.0345, -0.0503,  0.1665,  0.0461,\n",
              "        -0.2913, -0.2814, -0.0352, -0.1235, -0.1723,  0.2189, -0.0271,  0.2220,\n",
              "        -0.1080,  0.0976,  0.0646,  0.0567,  0.1021, -0.1718, -0.0557, -0.0740],\n",
              "       grad_fn=<MvBackward0>)"
            ]
          },
          "execution_count": 89,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "torch.matmul(first_layer.weight, concat_tensor)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4cd5e5c2",
      "metadata": {
        "id": "4cd5e5c2",
        "outputId": "54eb1548-a3f4-4cb0-c5ab-e762587390af"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([-0.1014, -0.0434,  0.1495,  0.0594, -0.1511, -0.0104, -0.0830, -0.0217,\n",
              "         0.0269,  0.1687,  0.2679,  0.0423,  0.1710, -0.0205, -0.1302, -0.3823,\n",
              "        -0.2216,  0.1646,  0.2188,  0.0234, -0.1152,  0.1256,  0.1081,  0.2385,\n",
              "         0.2288, -0.0017,  0.0467, -0.0243,  0.1805,  0.0397,  0.0331,  0.1226,\n",
              "         0.1068, -0.1220,  0.2065, -0.1513,  0.2422,  0.1978,  0.0621,  0.0944,\n",
              "         0.0589,  0.0851,  0.2401,  0.0359, -0.1163,  0.1025, -0.3653,  0.1052,\n",
              "         0.1608,  0.0969, -0.0260, -0.1708, -0.2358, -0.2242, -0.0224, -0.0895,\n",
              "         0.0413, -0.2420, -0.0761, -0.0006,  0.1911,  0.0721, -0.0274,  0.0084,\n",
              "         0.1376, -0.0117, -0.0238, -0.0739,  0.0417, -0.0189,  0.0175,  0.0612,\n",
              "         0.2436, -0.0954,  0.0930, -0.1291,  0.3059, -0.2236, -0.1336,  0.1935,\n",
              "         0.2372, -0.0942, -0.0061, -0.2416,  0.1701,  0.1200,  0.2148, -0.0873,\n",
              "        -0.0901, -0.1089, -0.1481, -0.0412,  0.2116, -0.0769, -0.1613, -0.1882,\n",
              "         0.1070, -0.1290, -0.0027, -0.0408, -0.2308, -0.1159,  0.3301, -0.0560,\n",
              "        -0.2788, -0.2808, -0.2233, -0.0059, -0.0345, -0.0503,  0.1665,  0.0461,\n",
              "        -0.2913, -0.2814, -0.0352, -0.1235, -0.1723,  0.2189, -0.0271,  0.2220,\n",
              "        -0.1080,  0.0976,  0.0646,  0.0567,  0.1021, -0.1718, -0.0557, -0.0740],\n",
              "       grad_fn=<SqueezeBackward3>)"
            ]
          },
          "execution_count": 90,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "first_layer(concat_tensor)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9af99d70",
      "metadata": {
        "id": "9af99d70",
        "outputId": "83320c14-d28b-41e5-97ef-e5580933e122"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([128, 1500])\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "tensor([ 0.0095, -0.0012,  0.0064,  ...,  0.0005,  0.0175,  0.0248],\n",
              "       grad_fn=<SelectBackward0>)"
            ]
          },
          "execution_count": 93,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "print(first_layer.weight.shape)\n",
        "first_layer.weight[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "86ab205d",
      "metadata": {
        "scrolled": true,
        "id": "86ab205d"
      },
      "outputs": [],
      "source": [
        "entire_output = []\n",
        "for neuron in first_layer.weight:\n",
        "  entire_output.append((neuron * concat_tensor).sum())\n",
        "# entire_output\n",
        "                    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b03c750c",
      "metadata": {
        "id": "b03c750c",
        "outputId": "df997b0b-f896-40d1-d947-110090616577"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['PAD', 'PAD', 'the', 'european', 'commission']"
            ]
          },
          "execution_count": 102,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "words_window"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f6dbee12",
      "metadata": {
        "scrolled": true,
        "id": "f6dbee12",
        "outputId": "edbeac07-db6e-4be0-efde-be18f6fd2d4d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([ 0.0054,  0.0077, -0.0163, -0.0124,  0.0235, -0.0194,  0.0113, -0.0191,\n",
              "        -0.0092, -0.0189, -0.0028, -0.0012,  0.0167, -0.0037,  0.0132, -0.0157,\n",
              "        -0.0244, -0.0151, -0.0135, -0.0045,  0.0148, -0.0084,  0.0058, -0.0123,\n",
              "        -0.0146,  0.0097, -0.0033, -0.0251,  0.0018, -0.0038,  0.0188,  0.0170,\n",
              "         0.0231,  0.0035,  0.0183, -0.0138,  0.0166,  0.0120, -0.0095, -0.0099,\n",
              "        -0.0049,  0.0172,  0.0048,  0.0203, -0.0244, -0.0243,  0.0124, -0.0147,\n",
              "        -0.0240,  0.0228, -0.0096,  0.0235,  0.0008,  0.0127,  0.0087,  0.0065,\n",
              "         0.0162, -0.0243, -0.0118, -0.0236, -0.0251,  0.0103, -0.0053,  0.0166,\n",
              "         0.0233,  0.0222,  0.0202,  0.0182,  0.0192,  0.0250, -0.0059,  0.0014,\n",
              "        -0.0155,  0.0045, -0.0057, -0.0007, -0.0106, -0.0187,  0.0243, -0.0133,\n",
              "         0.0140, -0.0190,  0.0144,  0.0083, -0.0186,  0.0147,  0.0073,  0.0174,\n",
              "         0.0132,  0.0005, -0.0211, -0.0121,  0.0253,  0.0171,  0.0217,  0.0058,\n",
              "         0.0232,  0.0018,  0.0053, -0.0236, -0.0203,  0.0121, -0.0074, -0.0142,\n",
              "        -0.0168,  0.0079,  0.0104,  0.0243,  0.0014,  0.0251, -0.0251,  0.0037,\n",
              "         0.0243, -0.0208, -0.0249,  0.0164, -0.0106, -0.0098,  0.0257,  0.0257,\n",
              "         0.0150, -0.0012, -0.0196, -0.0238, -0.0116, -0.0223, -0.0120, -0.0023,\n",
              "         0.0228, -0.0002,  0.0247, -0.0075, -0.0220,  0.0016,  0.0135, -0.0255,\n",
              "        -0.0185, -0.0058,  0.0103, -0.0191,  0.0006, -0.0226, -0.0098,  0.0105,\n",
              "         0.0148, -0.0085, -0.0140, -0.0253,  0.0053, -0.0154,  0.0254, -0.0095,\n",
              "         0.0107, -0.0026, -0.0088,  0.0098, -0.0019, -0.0209, -0.0004, -0.0203,\n",
              "         0.0188, -0.0193,  0.0246,  0.0095,  0.0025,  0.0089, -0.0010,  0.0030,\n",
              "         0.0251, -0.0254,  0.0079,  0.0126, -0.0191, -0.0033, -0.0227, -0.0256,\n",
              "        -0.0163, -0.0227, -0.0100,  0.0116,  0.0042,  0.0026, -0.0240, -0.0044,\n",
              "        -0.0223,  0.0051,  0.0097,  0.0222,  0.0168, -0.0200,  0.0145, -0.0001,\n",
              "        -0.0200, -0.0116, -0.0248, -0.0109, -0.0163, -0.0026,  0.0121,  0.0167,\n",
              "         0.0226, -0.0162, -0.0187, -0.0191,  0.0034,  0.0199,  0.0126,  0.0211,\n",
              "        -0.0155, -0.0176,  0.0042, -0.0202, -0.0194, -0.0126,  0.0047, -0.0224,\n",
              "        -0.0174,  0.0191, -0.0015, -0.0073,  0.0070,  0.0253, -0.0161, -0.0206,\n",
              "         0.0160,  0.0229, -0.0176, -0.0175,  0.0225, -0.0172, -0.0139, -0.0211,\n",
              "        -0.0039,  0.0036, -0.0003,  0.0147,  0.0083, -0.0070, -0.0241,  0.0223,\n",
              "        -0.0025, -0.0159,  0.0247,  0.0062, -0.0098,  0.0209,  0.0142, -0.0235,\n",
              "        -0.0136,  0.0206, -0.0036,  0.0247,  0.0109,  0.0188, -0.0123,  0.0070,\n",
              "         0.0157, -0.0207, -0.0034, -0.0212, -0.0140,  0.0189,  0.0248, -0.0182,\n",
              "        -0.0191,  0.0204,  0.0166, -0.0100,  0.0041,  0.0052, -0.0171, -0.0131,\n",
              "        -0.0153, -0.0184, -0.0138, -0.0062,  0.0237,  0.0079,  0.0216, -0.0198,\n",
              "        -0.0076, -0.0109,  0.0169, -0.0245, -0.0050, -0.0024,  0.0190,  0.0156,\n",
              "         0.0057,  0.0153,  0.0009, -0.0257, -0.0170, -0.0152, -0.0021, -0.0167,\n",
              "         0.0025, -0.0238, -0.0190, -0.0132], grad_fn=<SliceBackward0>)"
            ]
          },
          "execution_count": 106,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "first_layer.weight[0][600:900] #weight for the 600~900 which is 'the' dimension for 0th word\n",
        "#run the previous code: words_window\n",
        "#[0:300]will be PAD\n",
        "#[300:600]will be PAD\n",
        "#[600:900]will be the\n",
        "#[900:1200]will be european"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d8347386",
      "metadata": {
        "scrolled": true,
        "id": "d8347386",
        "outputId": "c34fa1aa-c732-4b59-d2b8-01c366bc944a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(tensor([-0.1014, -0.0434,  0.1495,  0.0594, -0.1511, -0.0104, -0.0830, -0.0217,\n",
              "          0.0269,  0.1687,  0.2679,  0.0423,  0.1710, -0.0205, -0.1302, -0.3823,\n",
              "         -0.2216,  0.1646,  0.2188,  0.0234], grad_fn=<SliceBackward0>),\n",
              " tensor([0.0000, 0.0000, 0.1495, 0.0594, 0.0000, 0.0000, 0.0000, 0.0000, 0.0269,\n",
              "         0.1687, 0.2679, 0.0423, 0.1710, 0.0000, 0.0000, 0.0000, 0.0000, 0.1646,\n",
              "         0.2188, 0.0234], grad_fn=<SliceBackward0>))"
            ]
          },
          "execution_count": 112,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "hidden = first_layer(concat_tensor)\n",
        "hidden_after_activation = torch.relu(hidden) #relu rotate and squeeze data\n",
        "hidden[:20], hidden_after_activation[:20]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9794d994",
      "metadata": {
        "id": "9794d994",
        "outputId": "b64677b6-40b3-47d7-88da-29c70aca18e5"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([128])"
            ]
          },
          "execution_count": 113,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "hidden.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ac60ded7",
      "metadata": {
        "id": "ac60ded7",
        "outputId": "c17aeb46-8c77-4ed9-bbf7-1d83430124ca"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([-0.0112], grad_fn=<AddBackward0>)"
            ]
          },
          "execution_count": 115,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "second_layer = nn.Linear(in_features=128, out_features=1)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "944dd4ea",
      "metadata": {
        "id": "944dd4ea",
        "outputId": "3c8bffe6-b109-4fcc-a111-c7b086891fdd"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(['PAD', 'PAD', 'the', 'european', 'commission'],\n",
              " tensor([0.4972], grad_fn=<SigmoidBackward0>))"
            ]
          },
          "execution_count": 125,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "second_output = second_layer(hidden_after_activation)\n",
        "final_prediction = torch.sigmoid(second_output)\n",
        "\n",
        "words_window, final_prediction\n",
        "#run the code\n",
        "#it means 0.4972 percent it predicts that it is the name entitiy of LOC "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "31b894da",
      "metadata": {
        "id": "31b894da",
        "outputId": "e9ee8252-9855-41de-e492-74b4e202814c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([0.5000])"
            ]
          },
          "execution_count": 121,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "torch.sigmoid(torch.zeros(1))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d1717281",
      "metadata": {
        "id": "d1717281"
      },
      "outputs": [],
      "source": [
        "get_words_window(sentence, word_idx, window_size)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "97b788b1",
      "metadata": {
        "id": "97b788b1",
        "outputId": "ae188951-1204-49c8-c651-5a4f22724c4d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['The DT B-NP O',\n",
              " 'European NNP I-NP B-ORG',\n",
              " 'Commission NNP I-NP I-ORG',\n",
              " 'said VBD B-VP O',\n",
              " 'on IN B-PP O']"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "sentence[:5]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f4fffd28",
      "metadata": {
        "id": "f4fffd28"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d3f8b574",
      "metadata": {
        "id": "d3f8b574"
      },
      "source": [
        "## 3. Make a Neural Network Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "05ef02f4",
      "metadata": {
        "id": "05ef02f4"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8baa6a67",
      "metadata": {
        "id": "8baa6a67"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c85a3ba8",
      "metadata": {
        "id": "c85a3ba8"
      },
      "source": [
        "## 4. Implement a train loop"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "74b595af",
      "metadata": {
        "id": "74b595af"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6dd30951",
      "metadata": {
        "id": "6dd30951"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6dce0efd",
      "metadata": {
        "id": "6dce0efd"
      },
      "source": [
        "## 5. Make Inference"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3fcf2a6c",
      "metadata": {
        "id": "3fcf2a6c"
      },
      "outputs": [],
      "source": [
        ""
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    },
    "colab": {
      "name": "“2. Named Entity Recognition Livecoding.ipynb”的副本",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}