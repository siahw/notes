{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "38583105",
      "metadata": {
        "id": "38583105"
      },
      "source": [
        "# Assignment 4: Attention\n",
        "- The assignment is still under construction.\n",
        "- But still, you can solve Problems 1 and 2\n",
        "- If you find any error, please do not hesitate to report or make a question on Cyber Campus\n",
        "    - Don't waste too much time on solving the error. The code is not thoroughly checked, and the error can be not your fault."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "095f3a9c",
      "metadata": {
        "id": "095f3a9c"
      },
      "outputs": [],
      "source": [
        "# If you are in Colab, install transformers \n",
        "!pip -q install transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8635fb79",
      "metadata": {
        "id": "8635fb79"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from pathlib import Path\n",
        "import pandas as pd\n",
        "from tqdm.auto import tqdm\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "from torch.nn.utils.rnn import PackedSequence, pad_sequence, pack_sequence, pad_packed_sequence, pack_padded_sequence\n",
        "from torch.utils.data import DataLoader\n",
        "from tokenizers import BertWordPieceTokenizer\n",
        "from transformers import BertTokenizerFast\n",
        "\n",
        "import os\n",
        "\n",
        "# Below helps to run tokenizer with multiprocessing\n",
        "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"true\"\n",
        "\n",
        "# Below helps to print Korean letters in plt\n",
        "def fix_font():\n",
        "    # From https://HC.Dle.pw, By Jinseo Kim\n",
        "    # v1.0.0\n",
        "    import os\n",
        "    import matplotlib as mpl\n",
        "    import matplotlib.pyplot as plt\n",
        "    os.system(\"apt-get install -y fonts-nanum\")\n",
        "    os.system(\"fc-cache -fv\")\n",
        "    mpl.font_manager._rebuild()\n",
        "    findfont = mpl.font_manager.fontManager.findfont\n",
        "    mpl.font_manager.findfont = findfont\n",
        "    mpl.backends.backend_agg.findfont = findfont\n",
        "    plt.rcParams['font.family'] = \"NanumBarunGothic\"\n",
        "    plt.rcParams['axes.unicode_minus'] = False\n",
        "\n",
        "try:\n",
        "  fix_font()\n",
        "except:\n",
        "  plt.rcParams['font.family'] = \"NanumBarunGothic\"\n",
        "  plt.rcParams['axes.unicode_minus'] = False"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ecd6024f",
      "metadata": {
        "id": "ecd6024f"
      },
      "source": [
        "#### Vectorization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f182b757",
      "metadata": {
        "scrolled": true,
        "id": "f182b757"
      },
      "outputs": [],
      "source": [
        "'''\n",
        "This is the example of vectorization of dot product for two different sequence length.\n",
        "'''\n",
        "\n",
        "e_states = torch.randn(100, 16)\n",
        "d_states = torch.randn(80, 16)\n",
        "\n",
        "dot_product = torch.mm(e_states, d_states.permute(1,0)) # (100, 16) x (16, 80) = (100, 80)\n",
        "dot_product"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fcfefeae",
      "metadata": {
        "id": "fcfefeae"
      },
      "source": [
        "## Problem 1: Implement Dot Product Attention (12 pts)\n",
        "\n",
        "- Optimizing computation time is really important\n",
        "    - Use `torch.mm()` or `torch.matmul()`\n",
        "    - `torch.mm(a, b)` is a function for calculating matrix multiplcation of two matrices `a` and `b`\n",
        "        - `a` and `b` has to be 2-dim tensors\n",
        "        - `a.shape[1]` has to be equal to `b.shape[0]`\n",
        "    - `torch.matmul()` is a function for matrix multiplication but with broadcasting\n",
        "        - https://pytorch.org/docs/stable/generated/torch.matmul.html\n",
        "        - It has less restriction on its input shape.\n",
        "            - It automatically matches the dimension of two tensors following some rules\n",
        "            - Therefore, it is a bit risky to use this funciton if you don't understand how it works"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2059e903",
      "metadata": {
        "id": "2059e903"
      },
      "source": [
        "### Hint: Dot product as matrix multiplcation.\n",
        "\n",
        "- Let's say there are two vector, $u=\\begin{bmatrix}-3 \\\\ 2 \\\\ 1\\end{bmatrix}$ and $v = \\begin{bmatrix} 5 \\\\ 4 \\\\ 6\\end{bmatrix}$\n",
        "    - The dot product of the two vectors is $(-3 \\times 5) + (2 \\times 4) + (1 \\times 6) = 1$\n",
        "    - It is equivalent to $u^T \\times v$\n",
        "        - In this case $u\\in\\mathbb{R}^{3x1}$ and $v\\in\\mathbb{R}^{3x1}$\n",
        "- In PyTorch, this can be described as below:\n",
        "    - `u = torch.Tensor([-3, 2, 1])`\n",
        "    - `v = torch.Tensor([5, 4, 6])`\n",
        "    - Dot product of u and v can be calculated by one of belows:\n",
        "        - `torch.mm(u.unsqueeze(0), v.unsqueeze(1))`\n",
        "            - `u.unsqueeze(0).shape == [1, 3]`\n",
        "            - `v.unsqueeze(1).shape == [3, 1]`\n",
        "            - `unsqueeze()` returns a new tensor with a dimension of size one inserted at the specified position.\n",
        "            - The result has shape of [1,1]\n",
        "        - `torch.matmul(u, v)`\n",
        "        - `u @ v`\n",
        "            - `@` denotes matrix multiplication, which was introduced from Python 3.5\n",
        "        - `(u * v).sum()`\n",
        "            - This will be much slower than others, because it first do element-wise multiplcation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a4aed8a2",
      "metadata": {
        "id": "a4aed8a2"
      },
      "outputs": [],
      "source": [
        "'''\n",
        "Hint: Dot product as matrix multiplcation.\n",
        "'''\n",
        "\n",
        "u = torch.Tensor([-3, 2, 1])\n",
        "v = torch.Tensor([5, 4, 6])\n",
        "\n",
        "print(f\"Result of (u * v).sum() is {(u * v).sum()}. This computation is much slower than others because it use element-wise multiplication instead of matrix multiplication\") \n",
        "print(f\"Result of torch.mm(u.unsqueeze(0), v.unsqueeze(1)) is {torch.mm(u.unsqueeze(0), v.unsqueeze(1))}\")\n",
        "print(f\"Result of torch.matmul(u, v) is {torch.matmul(u, v)}\")\n",
        "print(f\"Result of u @ v is {u @ v}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "66a20b45",
      "metadata": {
        "id": "66a20b45"
      },
      "outputs": [],
      "source": [
        "def get_attention_score_for_a_single_query(keys, query):\n",
        "  '''\n",
        "  This function returns an attention score for each vector in keys for a given query.\n",
        "  You can regard 'keys' as hidden states over timestep of Encoder, while query is a hidden state of specific time step of Decoder\n",
        "  Name 'keys' are used because it is used for calculating attention score (match rate between given vector and query).\n",
        "  \n",
        "  For every C-dimensional vector key, the attention score is a dot product between the key and the query vector.\n",
        "  \n",
        "  Arguments:\n",
        "    keys (torch.Tensor): Has a shape of [T, C]. These are vectors that a query wants attend to\n",
        "    query (torch.Tensor): Has a shape of [C]. This is a vector that attends to other set of vectors (keys and values)\n",
        "  \n",
        "  Output:\n",
        "    attention_score (torch.Tensor): The attention score in real number that represent how much does query have to attend to each vector in keys\n",
        "                                    Has a shape of [T]\n",
        "                                    \n",
        "    attention_score[i] has to be a dot product value between keys[i] and query                                 \n",
        "\n",
        "\n",
        "  TODO: Complete this sentence using torch.mm (matrix multiplication)\n",
        "  Hint: You can use atensor.unsqueeze(dim) to expand a dimension (with a diemsion of length 1) without changing item value of the tensor.\n",
        "  '''\n",
        "  \n",
        "  return\n",
        "\n",
        "\n",
        "torch.manual_seed(0)\n",
        "num_t = 23\n",
        "h_size = 16\n",
        "\n",
        "keys = torch.randn(num_t, h_size)\n",
        "query = torch.randn(h_size)\n",
        "\n",
        "att_score = get_attention_score_for_a_single_query(keys, query)\n",
        "att_score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ce66bf6c",
      "metadata": {
        "id": "ce66bf6c"
      },
      "outputs": [],
      "source": [
        "'''\n",
        "Test Case\n",
        "'''\n",
        "assert att_score.ndim == 1 and len(att_score) == num_t, \"Error: Check output shape\"\n",
        "answer = torch.Tensor([-3.0786,  2.1729,  1.7950, -5.0503,  3.3254,  0.2828, -0.9800, -1.8868,\n",
        "         0.2550,  2.9389, -0.1799, -1.0586,  0.1465, -0.9441,  0.8888, -3.8108,\n",
        "        -2.5662, -1.1660, -2.2327,  2.7087, -0.5800,  8.7984,  4.3816])\n",
        "assert torch.max(torch.abs(att_score-answer)) < 1e-4, \"Error: The output value is different\"\n",
        "print(\"Passed all the cases!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b63d332d",
      "metadata": {
        "id": "b63d332d"
      },
      "outputs": [],
      "source": [
        "def get_attention_weight_from_score(attention_score):\n",
        "  '''\n",
        "  This function converts attention score to attention weight.\n",
        "  \n",
        "  Argument:\n",
        "    attention_score (torch.Tensor): Tensor of real number. Has a shape of [T]\n",
        "\n",
        "  Output:\n",
        "    attention_weight (torch.Tensor): Tensor of real number between 0 and 1. Sum of attention_weight is 1. Has a shape of [T]\n",
        "  \n",
        "  TODO: Complete this function\n",
        "  '''\n",
        "  assert attention_score.ndim == 1\n",
        "  \n",
        "  return\n",
        "\n",
        "att_weight = get_attention_weight_from_score(att_score)\n",
        "att_weight"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8030b21a",
      "metadata": {
        "id": "8030b21a"
      },
      "outputs": [],
      "source": [
        "answer = torch.Tensor([0.0000,     0.0013,     0.0009,     0.0000,     0.0041,     0.0002,\n",
        "            0.0001,     0.0000,     0.0002,     0.0028,     0.0001,     0.0001,\n",
        "            0.0002,     0.0001,     0.0004,     0.0000,     0.0000,     0.0000,\n",
        "            0.0000,     0.0022,     0.0001,     0.9756,     0.0118])\n",
        "assert att_weight.shape == att_score.shape, 'Shape has to be remained the same'\n",
        "assert att_weight.sum() == 1, \"Sum of attention weight has to be 1\"\n",
        "assert torch.max(torch.abs(att_weight-answer)) < 1e-4, \"Error: The output value is different\"\n",
        "\n",
        "print(\"Passed all the cases!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6bf8e701",
      "metadata": {
        "id": "6bf8e701"
      },
      "outputs": [],
      "source": [
        "def get_weighted_sum(values, attention_weight):\n",
        "  '''\n",
        "  This function converts attention score to attention weight\n",
        "  \n",
        "  Argument:\n",
        "    values (torch.Tensor): Has a shape of [T, C]. These are vectors that are used to form attention vector\n",
        "    attention_weight: Has a shape of [T], which represents the weight for each vector to compose the attention vector\n",
        "\n",
        "  Output:\n",
        "    attention_vector (torch.Tensor): Weighted sum of values using the attention weight. Has a shape of [C]\n",
        "  \n",
        "  TODO: Complete this function using torch.mm\n",
        "  '''\n",
        "  return\n",
        "\n",
        "att_vec = get_weighted_sum(keys, att_weight) # In simple dot-product-attention, key and value are the same\n",
        "att_vec"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1253844f",
      "metadata": {
        "id": "1253844f"
      },
      "outputs": [],
      "source": [
        "answer = torch.Tensor([ 0.6280,  3.8540, -0.1042,  0.3148,  0.3711, -0.5095, -0.9663,  1.3295,\n",
        "         1.9003, -1.2611, -2.2939, -2.0338,  0.8757, -0.6726,  1.9071, -1.0711])\n",
        "assert att_vec.shape == query.shape, 'Shape has to be remained the same'\n",
        "assert torch.max(torch.abs(att_vec-answer)) < 1e-4, \"Error: The output value is different\"\n",
        "print(\"Passed all the cases\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cc00df77",
      "metadata": {
        "id": "cc00df77"
      },
      "source": [
        "## Problem 2: Attention in Batch ( 16 pts)\n",
        "- In this problem, you have to calculate attention with batch\n",
        "- You can use `torch.bmm()` for batch matrix multiplication https://pytorch.org/docs/stable/generated/torch.bmm.html \n",
        "    - `torch.bmm()` takes two 3-dim tensor as its input\n",
        "    - Each tensor has to be 3-dim (atensor.ndim==3)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "062446fe",
      "metadata": {
        "id": "062446fe"
      },
      "outputs": [],
      "source": [
        "'''\n",
        "Hint for Problem 2\n",
        "\n",
        "You can calculate matrix multiplication of matrices in batch effectively using torch.bmm() or torch.matmul()\n",
        "'''\n",
        "\n",
        "torch.manual_seed(0)\n",
        "matrix_left1 = torch.randn(5, 3)\n",
        "matrix_left2 = torch.randn(5, 3)\n",
        "\n",
        "print(f\"matrix_left1: \\n{matrix_left1}\")\n",
        "print(f\"matrix_left2: \\n{matrix_left2}\")\n",
        "\n",
        "matrix_right1 = torch.randn(3, 4)\n",
        "matrix_right2 = torch.randn(3, 4)\n",
        "print(f\"matrix_right1: \\n{matrix_right1}\")\n",
        "print(f\"matrix_right2: \\n{matrix_right2}\")\n",
        "\n",
        "print(\"Let's assume that we have batch of matrix, which is stack of these two matices\")\n",
        "matrix_left = torch.stack([matrix_left1, matrix_left2])\n",
        "matrix_right = torch.stack([matrix_right1, matrix_right2])\n",
        "\n",
        "print(f\"matrix_left: \\n{matrix_left} \\n which is shape of {matrix_left.shape}\")\n",
        "print(f\"matrix_right: \\n{matrix_right}\\n which is shape of {matrix_right.shape}\")\n",
        "\n",
        "\n",
        "'''\n",
        "Exhaustive method: using torch.mm() only with for loop (This is SLOW when matrix gets much larger)\n",
        "'''\n",
        "\n",
        "mm_forloop_output = []\n",
        "for sample_index in range(matrix_left.shape[0]):\n",
        "  mat_left = matrix_left[sample_index]\n",
        "  mat_right = matrix_right[sample_index]\n",
        "  \n",
        "  mm_result = torch.mm(mat_left, mat_right)\n",
        "  mm_forloop_output.append(mm_result)\n",
        "  \n",
        "mm_forloop_stack = torch.stack(mm_forloop_output)\n",
        "print(f\"mat_mul_stack: \\n{mm_forloop_stack}\\n which is shape of {mm_forloop_stack.shape}\")\n",
        "\n",
        "\n",
        "'''\n",
        "Good method: using torch.bmm()\n",
        "'''\n",
        "\n",
        "mat_mul_bmm = torch.bmm(matrix_left, matrix_right)\n",
        "print(f\"mat_mul_bmm: \\n{mat_mul_bmm}\\n which is shape of {mat_mul_bmm.shape}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fe689641",
      "metadata": {
        "id": "fe689641"
      },
      "outputs": [],
      "source": [
        "def get_attention_score_for_a_batch_query(keys, query):\n",
        "  '''\n",
        "  This function returns a batch of attention score for each vector in (multi-batch) keys for a given (single-batch) query.\n",
        "  You can regard 'keys' as hidden states over timestep of Encoder, while query is a hidden state of specific time step of Decoder\n",
        "  Name 'keys' are used because it is used for calculating attention score (match rate between given vector and query).\n",
        "  \n",
        "  For every C-dimensional vector key, the attention score is a dot product between the key and the query vector.\n",
        "  \n",
        "  Arguments:\n",
        "    keys (torch.Tensor): Has a shape of [N, T, C]. These are vectors that a query wants attend to\n",
        "    query (torch.Tensor): Has a shape of [N, C]. This is a vector that attends to other set of vectors (keys and values)\n",
        "  \n",
        "  Output:\n",
        "    attention_score (torch.Tensor): The attention score in real number that represent how much does query have to attend to each vector in keys\n",
        "                                    Has a shape of [N, T]\n",
        "                                    \n",
        "    attention_score[n, i] has to be a dot product value between keys[n, i] and query[n]                     \n",
        "    \n",
        "  TODO: Complete this function without using for loop\n",
        "  Hint: Use torch.bmm or torch.matmul after make two input tensors as 3-dim tensors.\n",
        "\n",
        "  '''\n",
        "  return \n",
        "\n",
        "torch.manual_seed(0)\n",
        "num_b = 6\n",
        "num_t = 23\n",
        "h_size = 16\n",
        "\n",
        "keys = torch.randn(num_b,num_t, h_size)\n",
        "query = torch.randn(num_b, h_size)\n",
        "out = get_attention_score_for_a_batch_query(keys, query)\n",
        "\n",
        "assert out.ndim == 2 and out.shape == torch.Size([num_b, num_t])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ae30995b",
      "metadata": {
        "scrolled": false,
        "id": "ae30995b"
      },
      "outputs": [],
      "source": [
        "def get_attention_score_for_a_batch_multiple_query(keys, queries):\n",
        "  '''\n",
        "  Now you have to implement the attention score for not only single query, but multiple queries.\n",
        "  \n",
        "  This function returns a batch of attention score for each vector in keys for given queries.\n",
        "  You can regard 'keys' as hidden states over timestep of Encoder, while querys are hidden states over timestep of Decoder\n",
        "  Name 'keys' are used because it is used for calculating attention score (match rate between given vector and query).\n",
        "  \n",
        "  For every C-dimensional vector key, the attention score is a dot product between the key and the query vector.\n",
        "  \n",
        "  Arguments:\n",
        "    keys (torch.Tensor): Has a shape of [N, Ts, C]. These are vectors that a query wants attend to\n",
        "    queries (torch.Tensor): Has a shape of [N, Tt, C]. This is a vector that attends to other set of vectors (keys and values)\n",
        "  \n",
        "  Output:\n",
        "    attention_score (torch.Tensor): The attention score in real number that represent how much does query have to attend to each vector in keys\n",
        "                                    Has a shape of [N, Ts, Tt]\n",
        "                                    \n",
        "    attention_score[n, i, t] has to be a dot product value between keys[n, i] and query[n, t] \n",
        "    \n",
        "  TODO: Complete this function without using for loop\n",
        "  HINT: Use torch.bmm() with proper transpose (permutation) of given tensors. (You can use atensor.permute())\n",
        "        Think about which dimension (axis) of tensors has to be multiplied together and resolved (disappear) after matrix multiplication,\n",
        "        and how the result tensor has to look like (shape)\n",
        "  '''\n",
        "  return\n",
        "\n",
        "torch.manual_seed(0)\n",
        "num_b = 6\n",
        "num_ts = 23\n",
        "num_tt = 14\n",
        "h_size = 16\n",
        "\n",
        "keys = torch.randn(num_b, num_ts, h_size)\n",
        "queries = torch.randn(num_b, num_tt, h_size)\n",
        "att_score = get_attention_score_for_a_batch_multiple_query(keys, queries)\n",
        "\n",
        "att_score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1cb45f70",
      "metadata": {
        "id": "1cb45f70"
      },
      "outputs": [],
      "source": [
        "'''\n",
        "Test cases\n",
        "'''\n",
        "answer = torch.Tensor([ 4.9620, -9.6091, -4.9472,  1.4543, -5.6273,  9.1436,  1.4172,  0.0464,\n",
        "        -5.7033,  4.5473,  7.7498,  1.3405, -3.1877,  2.8759])\n",
        "answer2 = torch.Tensor([[ 2.5171,  0.6216,  3.7929,  2.6163,  5.3290,  0.3592,  2.3067, -0.1099,\n",
        "         1.8963,  0.4175, -1.4283,  1.4388, -2.7825, -1.3690, -1.9615, -1.9514,\n",
        "        -6.4635,  1.9574,  0.1868,  8.5354,  4.6053,  2.8786, -2.1453]])\n",
        "assert att_score.ndim == 3 and att_score.shape == torch.Size([num_b, num_ts, num_tt]), 'Check the output shape'\n",
        "assert torch.max(torch.abs(att_score[2,4] - answer)) < 1e-4, 'Calculated result is wrong'\n",
        "assert torch.max(torch.abs(att_score[3,:,2] - answer2)) < 1e-4,  'Calculated result is wrong'\n",
        "\n",
        "print(\"Passed all the cases!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "19ef2611",
      "metadata": {
        "scrolled": false,
        "id": "19ef2611"
      },
      "outputs": [],
      "source": [
        "def get_masked_softmax(attention_score, mask, mask_value=-1e10):\n",
        "  '''\n",
        "  During the batch computation, each sequence in the batch can have different length.\n",
        "  To group them as in a single tensor, we usually pad values\n",
        "    \n",
        "  Arguments:\n",
        "    attention_score (torch.Tensor): The attention score in real number that represent how much does query have to attend to each vector in keys\n",
        "                                    Has a shape of [N, Ts, Tt]\n",
        "    mask (torch.Tensor): Boolean tensor with a shape of [N, Ts] that represents whether the corresponding is valid or not.\n",
        "                         mask[n, t] == 1 if and only if input_batch[n,t] is not a padded value.\n",
        "                         If input_batch[n,t] is a padded value, then mask[n,t] == 0\n",
        "  \n",
        "  Output:\n",
        "    attention_weight (torch.Tensor): The attention weight in real number between 0 and 1. The sum of attention_weight along keys timestep dimension is 1.\n",
        "                                    Has a shape of [N, Ts, Tt]\n",
        "                                    \n",
        "    attention_weight[n, i, t] has to be an attention weight of values[n, i] for queries[n, t] \n",
        "    \n",
        "  TODO: Complete this function without using for loop\n",
        "  Hint: You can give -infinity value by -float(\"inf\")\n",
        "\n",
        "  '''\n",
        "\n",
        "  return\n",
        "\n",
        "\n",
        "'''\n",
        "Don't change this codes\n",
        "'''\n",
        "mask = torch.ones_like(att_score)[..., 0]\n",
        "mask[4, 15:] = 0\n",
        "mask[5, 17:] = 0\n",
        "\n",
        "attention_weight = get_masked_softmax(att_score, mask)\n",
        "attention_weight"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "99abd97a",
      "metadata": {
        "id": "99abd97a"
      },
      "outputs": [],
      "source": [
        "answer = torch.Tensor([0.0120,     0.0002,     0.0901,     0.0003,     0.0259,     0.0036,\n",
        "            0.5617,     0.0108,     0.2508,     0.0054,     0.0001,     0.0010,\n",
        "            0.0000,     0.0005,     0.0375,     0.0000,     0.0000,     0.0000,\n",
        "            0.0000,     0.0000,     0.0000,     0.0000,     0.0000])\n",
        "assert torch.max(torch.abs(attention_weight[4,:,3]-answer)) < 1e-4\n",
        "assert torch.max(torch.abs(attention_weight.sum(1) -  1 )) < 1e-6"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9b2e5c36",
      "metadata": {
        "scrolled": true,
        "id": "9b2e5c36"
      },
      "outputs": [],
      "source": [
        "def get_batch_weighted_sum(values, attention_weight):\n",
        "  '''\n",
        "  This function converts attention score to attention weight\n",
        "  \n",
        "  Argument:\n",
        "    values (torch.Tensor): Has a shape of [N, Ts, C]. These are vectors that are used to form attention vector\n",
        "    attention_weight: Has a shape of [N, Ts, Tt], which represents the weight for each vector to compose the attention vector\n",
        "                      attention_weight[n, s, t] represents weight for value[n, s] that corresponds to a given query, queries[n, t]\n",
        "\n",
        "  Output:\n",
        "    attention_vector (torch.Tensor): Weighted sum of values using the attention weight. \n",
        "                                     Has a shape of [N, Tt, C]\n",
        "  \n",
        "  TODO: Complete this function using torch.mm\n",
        "  '''\n",
        "  \n",
        "  return\n",
        "\n",
        "att_out = get_batch_weighted_sum(keys, attention_weight)\n",
        "att_out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c93231ea",
      "metadata": {
        "id": "c93231ea"
      },
      "outputs": [],
      "source": [
        "'''\n",
        "Test cases\n",
        "'''\n",
        "answer = torch.Tensor([ 4.9620, -9.6091, -4.9472,  1.4543, -5.6273,  9.1436,  1.4172,  0.0464,\n",
        "        -5.7033,  4.5473,  7.7498,  1.3405, -3.1877,  2.8759])\n",
        "answer2 = torch.Tensor([[ 2.5171,  0.6216,  3.7929,  2.6163,  5.3290,  0.3592,  2.3067, -0.1099,\n",
        "         1.8963,  0.4175, -1.4283,  1.4388, -2.7825, -1.3690, -1.9615, -1.9514,\n",
        "        -6.4635,  1.9574,  0.1868,  8.5354,  4.6053,  2.8786, -2.1453]])\n",
        "assert att_score.ndim == 3 and att_score.shape == torch.Size([num_b, num_ts, num_tt]), 'Check the output shape'\n",
        "assert torch.max(torch.abs(att_score[2,4] - answer)) < 1e-4, 'Calculated result is wrong'\n",
        "assert torch.max(torch.abs(att_score[3,:,2] - answer2)) < 1e-4,  'Calculated result is wrong'\n",
        "\n",
        "print(\"Passed all the cases!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ebbdbf2b",
      "metadata": {
        "id": "ebbdbf2b"
      },
      "source": [
        "## Problem 3: Make seq2seq with attention (14 pts)\n",
        "- Using Pre-defined `TranslatorBi` class, complete a new `TranslatorAtt` class\n",
        "- If you implement it correctly, you can translate "
      ]
    },
    {
      "cell_type": "markdown",
      "id": "904d44a3",
      "metadata": {
        "id": "904d44a3"
      },
      "source": [
        "### 3-0 Prepare dataset and tokenizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9c670709",
      "metadata": {
        "id": "9c670709"
      },
      "outputs": [],
      "source": [
        "'''\n",
        "Download dataset (originally from NIA AI-Hub)\n",
        "'''\n",
        "\n",
        "!gdown 1CpsqOuuuB3I_PG5DbuqH1ssCFVerU46g\n",
        "!unzip -q nia-aihub-korean-english.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d4edd48e",
      "metadata": {
        "id": "d4edd48e"
      },
      "outputs": [],
      "source": [
        "dataset_dir = Path('nia_korean_english')\n",
        "data_list = sorted(list(dataset_dir.glob('*.xlsx')))\n",
        " \n",
        "# Use only first two xlsx files in the assignment\n",
        "data_list = data_list[:2]\n",
        "df = pd.concat([pd.read_excel(path) for path in data_list], axis=0)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4f310bde",
      "metadata": {
        "id": "4f310bde"
      },
      "source": [
        "### Download Pretrained Weights, and Tokenizers\n",
        "To use the pretrained model correctly, you can use the pretrained vocabularies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1b4d79f3",
      "metadata": {
        "id": "1b4d79f3"
      },
      "outputs": [],
      "source": [
        "!gdown 1lTo32Z9euLMSD1L1krgORceay9f-UU--\n",
        "!unzip nlp_assignment4.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "093978a4",
      "metadata": {
        "id": "093978a4"
      },
      "outputs": [],
      "source": [
        "'''\n",
        "for path in data_list:\n",
        "  df = pd.read_excel(path)\n",
        "  kor_text_path = path.parent / (path.stem+'_kor.txt') \n",
        "  eng_text_path = path.parent / (path.stem+'_eng.txt') \n",
        "  with open(kor_text_path, 'w', encoding='utf8') as f:\n",
        "      f.write('\\n'.join(df['원문']))\n",
        "  with open(eng_text_path, 'w', encoding='utf8') as f:\n",
        "      f.write('\\n'.join(df['번역문']))\n",
        "\n",
        "\n",
        "# Train Tokenizer\n",
        "tokenizer = BertWordPieceTokenizer(strip_accents=False, lowercase=False)\n",
        "\n",
        "vocab_size    = 32000  # Number of maximum size of the vocabulary\n",
        "limit_alphabet= 6000   \n",
        "min_frequency = 5 \n",
        "\n",
        "corpus_file   =  [str(path.parent / (path.stem + '_kor.txt')) for path in data_list]\n",
        "output_dir   = Path('hugging_kor_partial_%d'%(vocab_size))\n",
        "output_dir.mkdir(exist_ok=True)\n",
        "\n",
        "tokenizer.train(files=corpus_file,\n",
        "               vocab_size=vocab_size,\n",
        "               min_frequency=min_frequency,\n",
        "               limit_alphabet=limit_alphabet, \n",
        "               show_progress=True)\n",
        "\n",
        "tokenizer.save_model(str(output_dir))\n",
        "\n",
        "limit_alphabet= 200\n",
        "corpus_file   =  [str(path.parent / (path.stem + '_eng.txt')) for path in data_list]\n",
        "output_dir   = Path('hugging_eng_partial_%d'%(vocab_size))\n",
        "output_dir.mkdir(exist_ok=True)\n",
        "\n",
        "tokenizer.train(files=corpus_file,\n",
        "               vocab_size=vocab_size,\n",
        "               min_frequency=min_frequency,\n",
        "               limit_alphabet=limit_alphabet, \n",
        "               show_progress=True)\n",
        "\n",
        "tokenizer.save_model(str(output_dir))\n",
        "'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e7061145",
      "metadata": {
        "id": "e7061145"
      },
      "outputs": [],
      "source": [
        "src_tokenizer = BertTokenizerFast.from_pretrained('hugging_kor_32000',\n",
        "                                                       strip_accents=False,\n",
        "                                                       lowercase=False) \n",
        "tgt_tokenizer = BertTokenizerFast.from_pretrained('hugging_eng_32000',\n",
        "                                                       strip_accents=False,\n",
        "                                                       lowercase=False) \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ab8fa529",
      "metadata": {
        "id": "ab8fa529"
      },
      "outputs": [],
      "source": [
        "class TranslationSet:\n",
        "  def __init__(self, df, src_tokenizer, tgt_tokenizer):\n",
        "    self.data = df[ ['원문', '번역문']].values\n",
        "    self.src_tokenizer = src_tokenizer\n",
        "    self.tgt_tokenizer = tgt_tokenizer\n",
        "    \n",
        "  def __len__(self):\n",
        "    return len(self.data)\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "    src_str = self.data[idx, 0]\n",
        "    tgt_str = self.data[idx, 1]\n",
        "\n",
        "    # convert string to list of token ids\n",
        "    src_ids = self.src_tokenizer.encode(src_str)\n",
        "    tgt_ids = self.tgt_tokenizer.encode(tgt_str)\n",
        "\n",
        "    return torch.LongTensor(src_ids), torch.LongTensor(tgt_ids) # idx-th datasample\n",
        "  \n",
        "entireset = TranslationSet(df, src_tokenizer, tgt_tokenizer)\n",
        "trainset, validset, testset = torch.utils.data.random_split(entireset, [int(len(entireset)*0.9), int(len(entireset)*0.05), len(entireset)-int(len(entireset)*0.9)-int(len(entireset)*0.05)], generator=torch.Generator().manual_seed(42))\n",
        "# trainset, validset, testset = torch.utils.data.random_split(entireset, [360000, 20000, 20000], generator=torch.Generator().manual_seed(42))\n",
        "\n",
        "print(f'Dataset Item Example: {entireset[0]}')\n",
        "print(f'Length of split : Train {len(trainset)}, Valid {len(validset)}, Test {len(testset)}')\n",
        "\n",
        "def pack_collate(raw_batch):\n",
        "  srcs = [x[0] for x in raw_batch]\n",
        "  tgts_i = [x[1][:-1] for x in raw_batch]\n",
        "  tgts_o = [x[1][1:] for x in raw_batch]\n",
        "  \n",
        "  srcs = pack_sequence(srcs, enforce_sorted=False)\n",
        "  tgts_i = pack_sequence(tgts_i, enforce_sorted=False)\n",
        "  tgts_o = pack_sequence(tgts_o, enforce_sorted=False)\n",
        "  return srcs, tgts_i, tgts_o\n",
        "\n",
        "single_loader = DataLoader(trainset, batch_size=1, collate_fn=pack_collate, shuffle=True, num_workers=4, pin_memory=True)\n",
        "train_loader = DataLoader(trainset, batch_size=64, collate_fn=pack_collate, shuffle=True, num_workers=4, pin_memory=True)\n",
        "valid_loader = DataLoader(validset, batch_size=128, collate_fn=pack_collate, shuffle=False, num_workers=0, pin_memory=True)\n",
        "test_loader = DataLoader(testset, batch_size=128, collate_fn=pack_collate, shuffle=False, num_workers=0, pin_memory=True)\n",
        "\n",
        "batch = next(iter(train_loader))\n",
        "batch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a254bfb6",
      "metadata": {
        "id": "a254bfb6"
      },
      "outputs": [],
      "source": [
        "'''\n",
        "Pre-defined class\n",
        "'''\n",
        "\n",
        "\n",
        "class Trainer:\n",
        "  def __init__(self, model, optimizer, loss_fn, train_loader, valid_loader, device, model_name='nmt_model'):\n",
        "    self.model = model\n",
        "    self.optimizer = optimizer\n",
        "    self.loss_fn = loss_fn\n",
        "    self.train_loader = train_loader\n",
        "    self.valid_loader = valid_loader\n",
        "    \n",
        "    self.model.to(device)\n",
        "    \n",
        "    self.grad_clip = 1.0\n",
        "    self.best_valid_accuracy = 0\n",
        "    self.device = device\n",
        "    \n",
        "    self.training_loss = []\n",
        "    self.validation_loss = []\n",
        "    self.validation_acc = []\n",
        "    self.model_name = model_name\n",
        "\n",
        "  def save_model(self, path):\n",
        "    torch.save({'model':self.model.state_dict(), 'optim':self.optimizer.state_dict()}, path)\n",
        "    \n",
        "  def train_by_num_epoch(self, num_epochs):\n",
        "    for epoch in tqdm(range(num_epochs)):\n",
        "      self.model.train()\n",
        "      for batch in tqdm(self.train_loader, leave=False):\n",
        "        loss_value = self._train_by_single_batch(batch)\n",
        "        self.training_loss.append(loss_value)\n",
        "      self.model.eval()\n",
        "      validation_loss, validation_acc = self.validate()\n",
        "      self.validation_loss.append(validation_loss)\n",
        "      self.validation_acc.append(validation_acc)\n",
        "      \n",
        "      if validation_acc > self.best_valid_accuracy:\n",
        "        print(f\"Saving the model with best validation accuracy: Epoch {epoch+1}, Acc: {validation_acc:.4f} \")\n",
        "        self.save_model(f'{self.model_name}_best.pt')\n",
        "      else:\n",
        "        self.save_model(f'{self.model_name}_last.pt')\n",
        "      self.best_valid_accuracy = max(validation_acc, self.best_valid_accuracy)\n",
        "\n",
        "      \n",
        "  def _train_by_single_batch(self, batch):\n",
        "    '''\n",
        "    This method updates self.model's parameter with a given batch\n",
        "    \n",
        "    batch (tuple): (batch_of_input_text, batch_of_label)\n",
        "    \n",
        "    You have to use variables below:\n",
        "    \n",
        "    self.model (Translator/torch.nn.Module): A neural network model\n",
        "    self.optimizer (torch.optim.adam.Adam): Adam optimizer that optimizes model's parameter\n",
        "    self.loss_fn (function): function for calculating BCE loss for a given prediction and target\n",
        "    self.device (str): 'cuda' or 'cpu'\n",
        "\n",
        "    output: loss (float): Mean binary cross entropy value for every sample in the training batch\n",
        "    The model's parameters, optimizer's steps has to be updated inside this method\n",
        "    '''\n",
        "    \n",
        "    src, tgt_i, tgt_o = batch\n",
        "    pred = self.model(src.to(self.device), tgt_i.to(self.device))\n",
        "    loss = self.loss_fn(pred.data, tgt_o.data)\n",
        "    loss.backward()\n",
        "    torch.nn.utils.clip_grad_norm_(self.model.parameters(), self.grad_clip)\n",
        "    optimizer.step()\n",
        "    optimizer.zero_grad()\n",
        "    \n",
        "    return loss.item()\n",
        "\n",
        "    \n",
        "  def validate(self, external_loader=None):\n",
        "    '''\n",
        "    This method calculates accuracy and loss for given data loader.\n",
        "    It can be used for validation step, or to get test set result\n",
        "    \n",
        "    input:\n",
        "      data_loader: If there is no data_loader given, use self.valid_loader as default.\n",
        "      \n",
        "    output: \n",
        "      validation_loss (float): Mean Binary Cross Entropy value for every sample in validation set\n",
        "      validation_accuracy (float): Mean Accuracy value for every sample in validation set\n",
        "    '''\n",
        "    \n",
        "    ### Don't change this part\n",
        "    if external_loader and isinstance(external_loader, DataLoader):\n",
        "      loader = external_loader\n",
        "      print('An arbitrary loader is used instead of Validation loader')\n",
        "    else:\n",
        "      loader = self.valid_loader\n",
        "      \n",
        "    self.model.eval()\n",
        "    \n",
        "    '''\n",
        "    Write your code from here, using loader, self.model, self.loss_fn.\n",
        "    '''\n",
        "    validation_loss = 0\n",
        "    validation_acc = 0\n",
        "    num_total_tokens = 0\n",
        "    with torch.no_grad():\n",
        "      for batch in tqdm(loader, leave=False):\n",
        "        \n",
        "        src, tgt_i, tgt_o = batch\n",
        "        pred = self.model(src.to(self.device), tgt_i.to(self.device))\n",
        "        loss = self.loss_fn(pred.data, tgt_o.data)\n",
        "        num_tokens = tgt_i.data.shape[0]\n",
        "        validation_loss += loss.item() * num_tokens\n",
        "        num_total_tokens += num_tokens\n",
        "        \n",
        "        acc = torch.sum(torch.argmax(pred.data, dim=-1) == tgt_o.to(self.device).data)\n",
        "        validation_acc += acc.item()\n",
        "        \n",
        "    return validation_loss / num_total_tokens, validation_acc / num_total_tokens\n",
        "\n",
        "def get_cross_entropy_loss(predicted_prob_distribution, indices_of_correct_token):\n",
        "  '''\n",
        "  for PackedSequence, the input is 2D tensor\n",
        "  \n",
        "  predicted_prob_distribution has a shape of [num_entire_tokens_in_the_batch x vocab_size]\n",
        "  indices_of_correct_token has a shape of [num_entire_tokens_in_the_batch]\n",
        "  '''\n",
        "  prob_of_correct_next_word = predicted_prob_distribution[torch.arange(len(predicted_prob_distribution)), indices_of_correct_token]\n",
        "  loss = -torch.log(prob_of_correct_next_word)\n",
        "  return loss.mean()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "11a011e3",
      "metadata": {
        "id": "11a011e3"
      },
      "outputs": [],
      "source": [
        "'''\n",
        "Pre-defined class\n",
        "\n",
        "You don't need to change this code\n",
        "'''\n",
        "class TranslatorBi(nn.Module):\n",
        "  def __init__(self, src_tokenizer, tgt_tokenizer, hidden_size=256, num_layers=3):\n",
        "    super().__init__()\n",
        "    self.src_tokenizer = src_tokenizer\n",
        "    self.tgt_tokenizer = tgt_tokenizer\n",
        "    \n",
        "    self.src_vocab_size = self.src_tokenizer.vocab_size\n",
        "    self.tgt_vocab_size = self.tgt_tokenizer.vocab_size\n",
        "    \n",
        "    self.src_embedder = nn.Embedding(self.src_vocab_size, hidden_size)\n",
        "    self.tgt_embedder = nn.Embedding(self.tgt_vocab_size, hidden_size)\n",
        "    \n",
        "    self.encoder = nn.GRU(input_size=hidden_size, hidden_size=hidden_size, num_layers=num_layers, bidirectional=True, batch_first=True)\n",
        "    self.decoder = nn.GRU(input_size=hidden_size, hidden_size=hidden_size, num_layers=num_layers, batch_first=True)\n",
        "    \n",
        "    self.decoder_proj = nn.Linear(hidden_size, self.tgt_vocab_size)\n",
        "    \n",
        "  def run_encoder(self, x):\n",
        "    if isinstance(x, PackedSequence):\n",
        "      emb_x = PackedSequence(self.src_embedder(x.data), batch_sizes=x.batch_sizes, sorted_indices=x.sorted_indices, unsorted_indices=x.unsorted_indices)\n",
        "    else:\n",
        "      emb_x = self.src_embedder(x)\n",
        "      \n",
        "    enc_hidden_state_by_t, last_hidden = self.encoder(emb_x)\n",
        "    \n",
        "    # Because we use bi-directional GRU, there are (num_layers * 2) last hidden states\n",
        "    # Here, we make it to (num_layers) last hidden states by taking mean of [left-to-right-GRU] and [right-to-left-GRU]\n",
        "    last_hidden_sum = last_hidden.reshape(self.encoder.num_layers, 2, last_hidden.shape[1], -1).mean(dim=1)\n",
        "    if isinstance(x, PackedSequence):\n",
        "      hidden_mean = enc_hidden_state_by_t.data.reshape(-1, 2, last_hidden_sum.shape[-1]).mean(1)\n",
        "      enc_hidden_state_by_t = PackedSequence(hidden_mean, x[1], x[2], x[3])\n",
        "    else:\n",
        "      enc_hidden_state_by_t = enc_hidden_state_by_t.reshape(x.shape[0], x.shape[1], 2, -1).mean(dim=2)\n",
        "      \n",
        "    \n",
        "    return enc_hidden_state_by_t, last_hidden_sum \n",
        "\n",
        "  def run_decoder(self, y, last_hidden_state):\n",
        "    if isinstance(y, PackedSequence):\n",
        "      emb_y = PackedSequence(self.tgt_embedder(y.data), batch_sizes=y.batch_sizes, sorted_indices=y.sorted_indices, unsorted_indices=y.unsorted_indices)\n",
        "    else:\n",
        "      emb_y = self.tgt_embedder(y)\n",
        "    out, decoder_last_hidden = self.decoder(emb_y, last_hidden_state)\n",
        "    return out, decoder_last_hidden\n",
        "\n",
        "  def forward(self, x, y):\n",
        "    '''\n",
        "    x (torch.Tensor or PackedSequence): Batch of source sentences\n",
        "    y (torch.Tensor or PackedSequence): Batch of target sentences\n",
        "    '''\n",
        "    \n",
        "    enc_hidden_state_by_t, last_hidden_sum = self.run_encoder(x)\n",
        "    out, decoder_last_hidden = self.run_decoder(y, last_hidden_sum)\n",
        "    \n",
        "    if isinstance(out, PackedSequence):\n",
        "      logits = self.decoder_proj(out.data)\n",
        "      probs = torch.softmax(logits, dim=-1)\n",
        "      probs = PackedSequence(probs, batch_sizes=y.batch_sizes, sorted_indices=y.sorted_indices, unsorted_indices=y.unsorted_indices)\n",
        "    else:\n",
        "      logits = self.decoder_proj(out)\n",
        "      probs = torch.softmax(logits, dim=-1)\n",
        "    return probs\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2060d164",
      "metadata": {
        "id": "2060d164"
      },
      "source": [
        "### Problem 3.1: Complete the Seq2Seq with Attention\n",
        "- **Caution**: You have to concatenate [decoder_hidden_state; attention_out] for this implementation\n",
        "    - You can use different order of concatenation, but the pre-trained model used that specific order, so please follow it so that you can use the pre-trained weight correctly"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9e285f77",
      "metadata": {
        "scrolled": true,
        "id": "9e285f77"
      },
      "outputs": [],
      "source": [
        "class TranslatorAtt(TranslatorBi):\n",
        "  def __init__(self, src_tokenizer, tgt_tokenizer, hidden_size=512, num_layers=3):\n",
        "    super().__init__(src_tokenizer, tgt_tokenizer, hidden_size, num_layers)\n",
        "    \n",
        "    # TODO: define new self.decoder_proj\n",
        "    self.decoder_proj = nn.Linear(hidden_size * 2, self.tgt_vocab_size)\n",
        "    \n",
        "  def get_attention_vector(self, encoder_hidden_states, decoder_hidden_states, mask):\n",
        "    '''\n",
        "    Arguments:\n",
        "      x (torch.Tensor or PackedSequence)\n",
        "      y (torch.Tensor or PackedSequence)\n",
        "    Outputs:\n",
        "      attention_vectors (torch.Tensor or PackedSequence)\n",
        "    \n",
        "    TODO: Complete this function\n",
        "    If the inputs are PackedSequence, the output has to be a PackedSequence\n",
        "    Use torch.nn.utils.rnn.pad_packed_sequence(packed_sequence, batch_first=True)\n",
        "    '''\n",
        "    is_packed = isinstance(encoder_hidden_states, PackedSequence)\n",
        "    \n",
        "    # Write your code from here\n",
        "\n",
        "    return \n",
        "  \n",
        "  def forward(self, x, y):\n",
        "    '''\n",
        "    Arguments:\n",
        "      x (torch.Tensor or PackedSequence): Batch of source sentences\n",
        "      y (torch.Tensor or PackedSequence): Batch of target sentences\n",
        "    Output:\n",
        "      prob_dist (torch.Tensor or PackedSequence): Batch of probability distribution of word for target sentence\n",
        "    \n",
        "    TODO: Complete this function\n",
        "    '''\n",
        "\n",
        "    is_packed = isinstance(x, PackedSequence)\n",
        "    enc_hidden_state_by_t, last_hidden_sum = self.run_encoder(x)\n",
        "    dec_hidden_state_by_t, decoder_last_hidden = self.run_decoder(y, last_hidden_sum)\n",
        "    \n",
        "    if is_packed:\n",
        "      mask = pad_packed_sequence(x, batch_first=True)[0] != 0\n",
        "    else:\n",
        "      mask = torch.ones(x.shape[0], x.shape[1])\n",
        "    attention_vec = self.get_attention_vector(enc_hidden_state_by_t, dec_hidden_state_by_t, mask)\n",
        "\n",
        "    # Write your code from here\n",
        "    # For the concatenation, you have to concat [dec_hidden_state_by_t; attention_vec], not [attention_vec; dec_hidden_state_by_t]\n",
        "    return\n",
        "model = TranslatorAtt(src_tokenizer, tgt_tokenizer, hidden_size=32, num_layers=2)\n",
        "\n",
        "model(batch[0], batch[1])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3212344b",
      "metadata": {
        "id": "3212344b"
      },
      "source": [
        "#### Test your model\n",
        "- To evaluate your implementation, you have to load the pretrained weight of the same model.\n",
        "- If your implementation is correct, the resulting value would be the same"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3b291ec1",
      "metadata": {
        "id": "3b291ec1"
      },
      "outputs": [],
      "source": [
        "# Load pretrained weight\n",
        "model = TranslatorAtt(src_tokenizer, tgt_tokenizer, 512)\n",
        "state_dict = torch.load('nmt_attention_512_grad1_lr1e-4_best.pt', map_location='cpu')['model']\n",
        "model.eval()\n",
        "model.load_state_dict(state_dict)\n",
        "\n",
        "# Load the pre-calculated example and result\n",
        "prob3_values = torch.load('assignment_4_values.pt')\n",
        "single_batch_example, packed_batch_example, correct_single_out, correct_packed_out = prob3_values['single_test_batch'], prob3_values['packed_test_batch'], prob3_values['single_test_out'],  prob3_values['packed_test_out'] "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6051c11f",
      "metadata": {
        "id": "6051c11f"
      },
      "outputs": [],
      "source": [
        "'''\n",
        "Test Case for Single-size Batch\n",
        "'''\n",
        "single_out = model(single_batch_example[0], single_batch_example[1])\n",
        "\n",
        "assert isinstance(single_out, torch.Tensor), \"The output of model for Tensor has to be Tensor\"\n",
        "assert torch.max(torch.abs(single_out - correct_single_out)) < 1e-5, \"The output value is different from the expected\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8027b42c",
      "metadata": {
        "id": "8027b42c"
      },
      "outputs": [],
      "source": [
        "'''\n",
        "Test Case for Batch with PackedSequence\n",
        "'''\n",
        "packed_out = model(packed_batch_example[0], packed_batch_example[1])\n",
        "\n",
        "assert isinstance(packed_out, PackedSequence), \"The output of model for PackedSequence has to be PackedSequence\"\n",
        "assert (batch_out.batch_sizes == correct_packed_out.batch_sizes).all(), \"Output's batch_sizes is wrong\"\n",
        "assert (batch_out.sorted_indices == correct_packed_out.sorted_indices).all(), \"Output's sorted_indices is wrong\"\n",
        "\n",
        "assert torch.max(torch.abs(batch_out.data - correct_packed_out.data)) < 1e-5,  \"The output value is different from the expected\"\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "12e0ab23",
      "metadata": {
        "id": "12e0ab23"
      },
      "source": [
        "### Train the model (Optional)\n",
        "- You can try to train your model, but you can just load the pretrained data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "75d4bf8b",
      "metadata": {
        "id": "75d4bf8b"
      },
      "outputs": [],
      "source": [
        "model = TranslatorAtt(src_tokenizer, tgt_tokenizer, 512)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
        "\n",
        "trainer = Trainer(model, optimizer, get_cross_entropy_loss, train_loader, valid_loader, 'cuda', 'nmt_attention_512')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cea22364",
      "metadata": {
        "id": "cea22364"
      },
      "source": [
        "### Problem 3.2: Implement Inference with Attention Weights\n",
        "- In this problem, you have to implement an inference code that returns translation for given source sentence, but also **attention weights** between source sentence and target sentence"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1ef0e100",
      "metadata": {
        "id": "1ef0e100"
      },
      "outputs": [],
      "source": [
        "def translate(model, source_sentence):\n",
        "  '''\n",
        "  \n",
        "  Arguments:\n",
        "    model (TranslatorAtt): Translator model with attention\n",
        "    source_sentence (str): Sentence to translate\n",
        "\n",
        "  Returns:\n",
        "    input_tokens (list): Source sentence in a list of token in token_id\n",
        "    predicted_tokens (list): Translated sentence in a list of token in token_id\n",
        "    decoded_string (str): Translated sentence in string\n",
        "    attention_map (torch.Tensor): Attention weight between each token of source sentence and target sentence. Has a shape of [Ts, Tt]\n",
        "    \n",
        "  '''\n",
        "  \n",
        "  input_tokens = model.src_tokenizer.encode(source_sentence)\n",
        "  input_tensor = torch.LongTensor(input_tokens).unsqueeze(0)\n",
        "  mask = torch.ones_like(input_tensor)\n",
        "  enc_hidden_state_by_t, last_hidden_sum = model.run_encoder(input_tensor)\n",
        "  \n",
        "  # Setup for 0th step\n",
        "  current_hidden = last_hidden_sum\n",
        "  current_decoder_token = torch.LongTensor([[2]]) # start of sentence token\n",
        "  total_output = []\n",
        "  total_attetion_weights = []\n",
        "\n",
        "  for i in range(100): # You can chage it to while True:\n",
        "    emb = model.tgt_embedder(current_decoder_token)\n",
        "    '''\n",
        "    TODO: Complete the code here\n",
        "    \n",
        "    You have to \n",
        "      1) run decoder rnn for a single step\n",
        "      2) get attention weight (variable name: att_weight) and attention vector.\n",
        "         att_weight.shape == torch.Size([1, len(tokenized_sentence), 1])\n",
        "      3) concat decoder out and attention vector\n",
        "      4) calculate probabilty logit (variable name: logit)\n",
        "    '''\n",
        "\n",
        "\n",
        "    if current_decoder_token == 3: ## end of sentence token\n",
        "      break\n",
        "    total_output.append(selected_token[0])\n",
        "    total_attetion_weights.append(att_weight[0,:,0])\n",
        "  predicted_tokens = torch.cat(total_output, dim=0).tolist()\n",
        "  attention_map = torch.stack(total_attetion_weights, dim=1)\n",
        "  \n",
        "  return  input_tokens, predicted_tokens, model.tgt_tokenizer.decode(predicted_tokens), attention_map\n",
        "\n",
        "model.cpu()\n",
        "input_tokens, pred_tokens, translated_string, att_weights  = translate(model, '이 알고리즘을 사용하면 한국어 단어와 영어 단어가 어떻게 연결되는지를 알 수 있습니다.')\n",
        "print(translated_string)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e466b4f4",
      "metadata": {
        "id": "e466b4f4"
      },
      "source": [
        "### Plot attention map\n",
        "- If you completed `translate()`, you can visualize the result of attention weight as below"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f1bf81f6",
      "metadata": {
        "id": "f1bf81f6"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(len(pred_tokens)*0.8, len(input_tokens)*0.8))\n",
        "x_axis_label = [model.tgt_tokenizer.decode(x) for x in pred_tokens]\n",
        "y_axis_label = [model.src_tokenizer.decode(x) for x in input_tokens]\n",
        "\n",
        "plt.imshow(att_weights.detach())\n",
        "plt.xticks(range(len(x_axis_label)), x_axis_label, fontsize=15,rotation = 45)\n",
        "plt.yticks(range(len(y_axis_label)), y_axis_label, fontsize=15)\n",
        "None"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d7292462",
      "metadata": {
        "id": "d7292462"
      },
      "source": [
        "## Problem 4: Self Attention (8 pts)\n",
        "- In this problem, you will implement the key-query-value calculation that was used for Transformer\n",
        "- Also, you have to implement simple self-attention (without multiheaded attention)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "35fb7765",
      "metadata": {
        "id": "35fb7765"
      },
      "outputs": [],
      "source": [
        "def get_key_query_value(input_tensor, kqv_layer):\n",
        "  '''\n",
        "  This function returns key, query, and value that is calculated by input tensor and nn_layer.\n",
        "\n",
        "  Arguments:\n",
        "    input_tensor (torch.Tensor): Has a shape of [N, T, C]\n",
        "    kqv_layer (torch.nn.Linear): Linear layer with in_features=C and out_features=Cn * 3\n",
        "    \n",
        "  Outputs:\n",
        "    keys (torch.Tensor): Has a shape of [N, T, Cn]\n",
        "    queries (torch.Tensor): Has a shape of [N, T, Cn]\n",
        "    values (torch.Tensor): Has a shape of [N, T, Cn]\n",
        "    \n",
        "  Hint: Use torch.chunk() to split a tensor into given number of chunks\n",
        "  '''\n",
        "  return \n",
        "\n",
        "torch.manual_seed(0)\n",
        "test = torch.randn(4, 17, 8)\n",
        "linear = nn.Linear(8, 16 * 3)\n",
        "keys, queries, values = get_key_query_value(test, linear)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "82c0cae6",
      "metadata": {
        "id": "82c0cae6"
      },
      "outputs": [],
      "source": [
        "'''\n",
        "Test cases\n",
        "'''\n",
        "answer = torch.Tensor([-0.6166,  0.2079, -0.0225, -0.2324,  0.0254,  0.0093,  0.2242, -0.4207,\n",
        "         0.1735, -0.3859,  0.1021, -0.4263,  0.6088,  0.2397,  0.7548,  0.0349])\n",
        "answer2 = torch.Tensor([[ 0.8704, -0.2256,  0.6611,  0.0332, -0.5233, -0.1159,  0.1805,  0.7238,\n",
        "         0.5590,  0.7260,  1.3096,  0.2465,  1.1961,  0.1751, -0.9674,  0.6297]])\n",
        "assert keys.ndim == queries.ndim == values.ndim == 3\n",
        "assert keys.shape == queries.shape == values.shape == torch.Size([4, 17, 16])\n",
        "assert not (keys==queries).any() and not (keys==values).any() and not (values==queries).any()\n",
        "assert torch.max(torch.abs(queries[2, 13]-answer)) < 1e-4\n",
        "assert torch.max(torch.abs(values[0, 3]-answer2)) < 1e-4\n",
        "\n",
        "print('Passed all the cases!')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7dc503bd",
      "metadata": {
        "id": "7dc503bd"
      },
      "outputs": [],
      "source": [
        "def get_self_attention(input_tensor, kqv_layer, mask):\n",
        "  '''\n",
        "  This function returns output of self-attention for a given input tensor using with a given kqv_layer\n",
        "  \n",
        "  Arguments:\n",
        "    input_tensor (torch.Tensor): Has a shape of [N, T, C]\n",
        "    kqv_layer (torch.nn.Linear): Linear layer with in_features=C and out_features=Cn * 3\n",
        "    mask (torch.Tensor): \n",
        "    \n",
        "  Outputs:\n",
        "    output (torch.Tensor): Has a shape of [N, T, Cn]\n",
        "\n",
        "  TODO: Complete this function using your completed functions of below:\n",
        "        get_attention_score_for_a_batch_multiple_query()\n",
        "        get_masked_softmax()\n",
        "        get_batch_weighted_sum()\n",
        "        get_key_query_value()\n",
        "  '''\n",
        "  return\n",
        "\n",
        "\n",
        "torch.manual_seed(0)\n",
        "test = torch.randn(4, 17, 8)\n",
        "linear = nn.Linear(8, 16 * 3)\n",
        "mask = torch.ones_like(test)[..., 0]\n",
        "mask[2, 4:] = 0\n",
        "mask[3, 14:] = 0\n",
        "\n",
        "att_vecs = get_self_attention(test, linear, mask)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "602218f9",
      "metadata": {
        "id": "602218f9"
      },
      "outputs": [],
      "source": [
        "'''\n",
        "Test cases\n",
        "'''\n",
        "answer = torch.Tensor([-0.3316,  0.1992,  0.1699, -0.3703, -0.2126, -0.0147,  0.1185, -0.2360,\n",
        "         0.2283,  0.1729,  0.0460,  0.1587,  0.1891,  0.4584, -0.3860,  0.0854])\n",
        "answer2 = torch.Tensor([-0.9989,  0.4320,  0.0282, -0.6165, -0.0183,  0.1410,  0.6790, -1.3118,\n",
        "         0.1059, -0.7182, -0.5426,  0.1642, -0.6460,  0.8397,  0.4638,  0.1082])\n",
        "assert keys.ndim == queries.ndim == values.ndim == 3\n",
        "assert keys.shape == queries.shape == values.shape == torch.Size([4, 17, 16])\n",
        "assert not (keys==queries).any() and not (keys==values).any() and not (values==queries).any()\n",
        "assert torch.max(torch.abs(att_vecs[3, 2]-answer)) < 1e-4\n",
        "assert torch.max(torch.abs(att_vecs[0, 11]-answer2)) < 1e-4\n",
        "\n",
        "\n",
        "print('Passed all the cases!')"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    },
    "colab": {
      "name": "Assignment_4.ipynb",
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}